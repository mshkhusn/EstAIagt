# app.py
import os
import re
import json
import importlib
from io import BytesIO
from datetime import date
import ast

import streamlit as st
import pandas as pd
import google.generativeai as genai
from dateutil.relativedelta import relativedelta

# ===== openpyxl / Excel =====
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell
from openpyxl.utils import column_index_from_string, get_column_letter

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================
st.set_page_config(page_title="æ˜ åƒåˆ¶ä½œæ¦‚ç®—è¦‹ç©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ vNext", layout="centered")

# =========================
# Secrets
# =========================
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
APP_PASSWORD   = st.secrets["APP_PASSWORD"]

genai.configure(api_key=GEMINI_API_KEY)
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# =========================
# OpenAI åˆæœŸåŒ–ï¼ˆv1/v0 ä¸¡å¯¾å¿œï¼‰
# =========================
USE_OPENAI_CLIENT_V1 = False
openai_client = None
openai_version = "unknown"
try:
    from openai import OpenAI as _OpenAI
    openai_client = _OpenAI()
    USE_OPENAI_CLIENT_V1 = True
    try:
        mod = importlib.import_module("openai")
        openai_version = getattr(mod, "__version__", "1.x")
    except Exception:
        openai_version = "1.x"
except Exception:
    import openai as _openai
    _openai.api_key = OPENAI_API_KEY
    openai_client = _openai
    USE_OPENAI_CLIENT_V1 = False
    openai_version = getattr(openai_client, "__version__", "0.x")

# =========================
# å®šæ•°
# =========================
TAX_RATE = 0.10
MGMT_FEE_CAP_RATE = 0.15
RUSH_K = 0.75

# ===== å¿…é ˆå‡ºç¾ã‚¿ã‚¯ã‚½ãƒãƒŸãƒ¼ï¼ˆç¶²ç¾…ã‚¢ãƒ³ã‚«ãƒ¼ï¼‰ =====
DETAIL_TAXONOMY = {
    "åˆ¶ä½œäººä»¶è²»": [
        "åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼","åˆ¶ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼","åˆ¶ä½œé€²è¡Œ","ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼",
        "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼","ã‚«ãƒ¡ãƒ©ãƒãƒ³","æ’®å½±åŠ©æ‰‹","ç…§æ˜","éŒ²éŸ³","DIT",
        "ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ","ãƒ˜ã‚¢ãƒ¡ã‚¤ã‚¯","ç¾è¡“ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼","å¤§é“å…·","å°é“å…·","ãƒ­ã‚±ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼"
    ],
    "ä¼ç”»": [
        "ä¼ç”»æ§‹æˆ","æ¼”å‡ºã‚³ãƒ³ãƒ†åˆ¶ä½œè²»","çµµã‚³ãƒ³ãƒ†/ã‚³ãƒ³ãƒ†","å°æœ¬ä½œæˆ","ãƒ­ã‚±ãƒãƒ³è²»","æ’®å½±è¨±èªå¯ç”³è«‹è²»"
    ],
    "æ’®å½±è²»": [
        "ã‚¹ã‚¿ã‚¸ã‚ªè²»","ãƒ­ã‚±è²»","è»Šä¸¡/æ¬å…¥å‡º","ã‚«ãƒ¡ãƒ©æ©Ÿæ","ãƒ¬ãƒ³ã‚º","ç…§æ˜æ©Ÿæ","éŸ³å£°æ©Ÿæ","ãƒ‰ãƒ­ãƒ¼ãƒ³","ã‚°ãƒªãƒ¼ãƒ³ãƒãƒƒã‚¯"
    ],
    "å‡ºæ¼”é–¢é€£è²»": [
        "ã‚­ãƒ£ã‚¹ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰","ã‚¨ã‚­ã‚¹ãƒˆãƒ©","ã‚¿ãƒ¬ãƒ³ãƒˆä½¿ç”¨æ–™ï¼ˆè©²å½“æ™‚ï¼‰","ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°è²»","è¡£è£…/ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°","äº¤é€š/ã‚±ãƒ¼ã‚¿ãƒªãƒ³ã‚°"
    ],
    "ç·¨é›†è²»ãƒ»MAè²»": [
        "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç·¨é›†","ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç·¨é›†","ã‚«ãƒ©ã‚³ãƒ¬/ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°","VFX/CG","ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹",
        "å­—å¹•åˆ¶ä½œ","MA","ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åéŒ²/ã‚¹ã‚¿ã‚¸ã‚ª","BGMãƒ©ã‚¤ã‚»ãƒ³ã‚¹/ä½œæ›²"
    ],
    "è«¸çµŒè²»": [
        "ãƒ‡ãƒ¼ã‚¿ç®¡ç†/ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—","äºˆå‚™æ—¥","ä¿é™º","é›‘è²»/é€šä¿¡è²»","ç´å“ãƒ‡ãƒ¼ã‚¿å¤‰æ›/è¤‡æ•°æ›¸ãå‡ºã—"
    ],
    "ç®¡ç†è²»": ["ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰"]
}

# ===== ã‚¹ãƒ‘ãƒ¼ã‚¹æ¤œå‡ºã—ãã„å€¤ =====
MIN_TOTAL_ITEMS = 20  # ç®¡ç†è²»ã‚’é™¤ãæœ€ä½è¡Œæ•°
MIN_PER_CATEGORY = {
    "åˆ¶ä½œäººä»¶è²»": 6,
    "ä¼ç”»": 3,
    "æ’®å½±è²»": 5,
    "å‡ºæ¼”é–¢é€£è²»": 3,
    "ç·¨é›†è²»ãƒ»MAè²»": 5,
    "è«¸çµŒè²»": 3
}

# ====== ç›¸å ´ãƒ¬ãƒ³ã‚¸ï¼ˆ1æ—¥ or 1å¼å˜ä¾¡ã®ç›®å®‰ï¼‰ ======
RATE_TABLE = {
    # åˆ¶ä½œäººä»¶è²»
    "åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼": {"unit":"æ—¥","low":70000,"mid":90000,"high":120000},
    "åˆ¶ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼": {"unit":"æ—¥","low":60000,"mid":80000,"high":100000},
    "åˆ¶ä½œé€²è¡Œ": {"unit":"æ—¥","low":50000,"mid":65000,"high":80000},
    "ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼": {"unit":"æ—¥","low":90000,"mid":120000,"high":150000},
    "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼": {"unit":"æ—¥","low":50000,"mid":60000,"high":75000},
    "ã‚«ãƒ¡ãƒ©ãƒãƒ³": {"unit":"æ—¥","low":70000,"mid":90000,"high":120000},
    "æ’®å½±åŠ©æ‰‹": {"unit":"æ—¥","low":35000,"mid":45000,"high":60000},
    "ç…§æ˜": {"unit":"æ—¥","low":60000,"mid":80000,"high":100000},
    "éŒ²éŸ³": {"unit":"æ—¥","low":55000,"mid":70000,"high":90000},
    "DIT": {"unit":"æ—¥","low":45000,"mid":60000,"high":80000},
    "ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ": {"unit":"æ—¥","low":55000,"mid":70000,"high":90000},
    "ãƒ˜ã‚¢ãƒ¡ã‚¤ã‚¯": {"unit":"æ—¥","low":50000,"mid":65000,"high":80000},
    "ç¾è¡“ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼": {"unit":"æ—¥","low":65000,"mid":80000,"high":110000},
    "å¤§é“å…·": {"unit":"æ—¥","low":35000,"mid":45000,"high":60000},
    "å°é“å…·": {"unit":"æ—¥","low":30000,"mid":40000,"high":55000},
    "ãƒ­ã‚±ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼": {"unit":"æ—¥","low":50000,"mid":65000,"high":85000},

    # ä¼ç”»
    "ä¼ç”»æ§‹æˆ": {"unit":"å¼","low":70000,"mid":90000,"high":130000},
    "æ¼”å‡ºã‚³ãƒ³ãƒ†åˆ¶ä½œè²»": {"unit":"å¼","low":50000,"mid":70000,"high":100000},
    "çµµã‚³ãƒ³ãƒ†/ã‚³ãƒ³ãƒ†": {"unit":"å¼","low":50000,"mid":70000,"high":100000},
    "å°æœ¬ä½œæˆ": {"unit":"å¼","low":50000,"mid":70000,"high":100000},
    "ãƒ­ã‚±ãƒãƒ³è²»": {"unit":"æ—¥","low":40000,"mid":50000,"high":70000},
    "æ’®å½±è¨±èªå¯ç”³è«‹è²»": {"unit":"å¼","low":20000,"mid":30000,"high":60000},

    # æ’®å½±è²»
    "ã‚¹ã‚¿ã‚¸ã‚ªè²»": {"unit":"æ—¥","low":60000,"mid":80000,"high":150000},
    "ãƒ­ã‚±è²»": {"unit":"æ—¥","low":50000,"mid":70000,"high":120000},
    "è»Šä¸¡/æ¬å…¥å‡º": {"unit":"æ—¥","low":30000,"mid":40000,"high":60000},
    "ã‚«ãƒ¡ãƒ©æ©Ÿæ": {"unit":"æ—¥","low":50000,"mid":80000,"high":120000},
    "ãƒ¬ãƒ³ã‚º": {"unit":"æ—¥","low":20000,"mid":40000,"high":80000},
    "ç…§æ˜æ©Ÿæ": {"unit":"æ—¥","low":40000,"mid":60000,"high":90000},
    "éŸ³å£°æ©Ÿæ": {"unit":"æ—¥","low":20000,"mid":30000,"high":60000},
    "ãƒ‰ãƒ­ãƒ¼ãƒ³": {"unit":"æ—¥","low":80000,"mid":100000,"high":150000},
    "ã‚°ãƒªãƒ¼ãƒ³ãƒãƒƒã‚¯": {"unit":"æ—¥","low":30000,"mid":40000,"high":70000},

    # å‡ºæ¼”é–¢é€£è²»
    "ã‚­ãƒ£ã‚¹ãƒˆï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰": {"unit":"äºº","low":30000,"mid":50000,"high":100000},
    "ã‚¨ã‚­ã‚¹ãƒˆãƒ©": {"unit":"äºº","low":8000,"mid":12000,"high":20000},
    "ã‚¿ãƒ¬ãƒ³ãƒˆä½¿ç”¨æ–™ï¼ˆè©²å½“æ™‚ï¼‰": {"unit":"å¼","low":200000,"mid":400000,"high":1000000},
    "ã‚­ãƒ£ã‚¹ãƒ†ã‚£ãƒ³ã‚°è²»": {"unit":"å¼","low":50000,"mid":70000,"high":120000},
    "è¡£è£…/ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°": {"unit":"å¼","low":20000,"mid":30000,"high":60000},
    "äº¤é€š/ã‚±ãƒ¼ã‚¿ãƒªãƒ³ã‚°": {"unit":"æ—¥","low":15000,"mid":20000,"high":40000},

    # ç·¨é›†ãƒ»MA
    "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç·¨é›†": {"unit":"æ—¥","low":60000,"mid":80000,"high":120000},
    "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç·¨é›†": {"unit":"æ—¥","low":70000,"mid":90000,"high":140000},
    "ã‚«ãƒ©ã‚³ãƒ¬/ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°": {"unit":"æ—¥","low":60000,"mid":80000,"high":120000},
    "VFX/CG": {"unit":"æ—¥","low":80000,"mid":100000,"high":160000},
    "ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹": {"unit":"æ—¥","low":70000,"mid":90000,"high":140000},
    "å­—å¹•åˆ¶ä½œ": {"unit":"å¼","low":20000,"mid":30000,"high":60000},
    "MA": {"unit":"æ—¥","low":50000,"mid":70000,"high":100000},
    "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åéŒ²/ã‚¹ã‚¿ã‚¸ã‚ª": {"unit":"å¼","low":50000,"mid":70000,"high":120000},
    "BGMãƒ©ã‚¤ã‚»ãƒ³ã‚¹/ä½œæ›²": {"unit":"å¼","low":40000,"mid":60000,"high":120000},

    # è«¸çµŒè²»
    "ãƒ‡ãƒ¼ã‚¿ç®¡ç†/ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—": {"unit":"å¼","low":15000,"mid":20000,"high":40000},
    "äºˆå‚™æ—¥": {"unit":"æ—¥","low":50000,"mid":60000,"high":80000},
    "ä¿é™º": {"unit":"å¼","low":10000,"mid":15000,"high":30000},
    "é›‘è²»/é€šä¿¡è²»": {"unit":"å¼","low":8000,"mid":12000,"high":20000},
    "ç´å“ãƒ‡ãƒ¼ã‚¿å¤‰æ›/è¤‡æ•°æ›¸ãå‡ºã—": {"unit":"å¼","low":15000,"mid":20000,"high":40000},
}

CATEGORY_DEFAULT_UNIT = {
    "åˆ¶ä½œäººä»¶è²»": "æ—¥",
    "ä¼ç”»": "å¼",
    "æ’®å½±è²»": "æ—¥",
    "å‡ºæ¼”é–¢é€£è²»": "äºº",
    "ç·¨é›†è²»ãƒ»MAè²»": "æ—¥",
    "è«¸çµŒè²»": "å¼",
    "ç®¡ç†è²»": "å¼",
}

# ====== è£œæ­£ä¿‚æ•° ======
MARKET_MULT = {
    "æ—¥æœ¬å…¨å›½å¹³å‡": 1.00,
    "é¦–éƒ½åœï¼ˆæ±äº¬è¿‘éƒŠï¼‰": 1.15,
    "åœ°æ–¹éƒ½å¸‚": 0.90,
}
CREW_GRADE_MULT = {
    "ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰": 1.00,
    "ã‚¸ãƒ¥ãƒ‹ã‚¢": 0.90,
    "ã‚·ãƒ‹ã‚¢": 1.20,
}
SCALE_MULT = {
    "å°": 0.90,
    "ä¸­": 1.00,
    "å¤§": 1.20,
}
FEATURE_MULT = {
    "CG": 1.10,
    "ã‚¿ãƒ¬ãƒ³ãƒˆ": 1.15,
    "å¤šæ•°ç‰ˆæ›¸ãå‡ºã—": 1.05,
}

GLOBAL_FALLBACK_UNIT_PRICE = 30000  # æœ€çµ‚ä¿é™º

# =========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³
# =========================
for k in ["items_json_raw", "items_json", "df", "meta", "final_html"]:
    if k not in st.session_state:
        st.session_state[k] = None

# =========================
# èªè¨¼
# =========================
st.title("æ˜ åƒåˆ¶ä½œæ¦‚ç®—è¦‹ç©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ vNext")
password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
if password != APP_PASSWORD:
    st.warning("ğŸ”’ èªè¨¼ãŒå¿…è¦ã§ã™")
    st.stop()

# =========================
# å…¥åŠ›
# =========================
st.header("åˆ¶ä½œæ¡ä»¶ã®å…¥åŠ›")
video_duration = st.selectbox("å°ºã®é•·ã•", ["15ç§’", "30ç§’", "60ç§’", "ãã®ä»–"])
final_duration = st.text_input("å°ºã®é•·ã•ï¼ˆè‡ªç”±è¨˜å…¥ï¼‰") if video_duration == "ãã®ä»–" else video_duration
num_versions = st.number_input("ç´å“æœ¬æ•°", min_value=1, max_value=10, value=1)
shoot_days = st.number_input("æ’®å½±æ—¥æ•°", min_value=1, max_value=10, value=2)
edit_days = st.number_input("ç·¨é›†æ—¥æ•°", min_value=1, max_value=10, value=3)
delivery_date = st.date_input("ç´å“å¸Œæœ›æ—¥", value=date.today() + relativedelta(months=1))
cast_main = st.number_input("ãƒ¡ã‚¤ãƒ³ã‚­ãƒ£ã‚¹ãƒˆäººæ•°", 0, 10, 1)
cast_extra = st.number_input("ã‚¨ã‚­ã‚¹ãƒˆãƒ©äººæ•°", 0, 20, 0)
talent_use = st.checkbox("ã‚¿ãƒ¬ãƒ³ãƒˆèµ·ç”¨ã‚ã‚Š")

default_roles = [
    "åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼", "åˆ¶ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼", "ã‚«ãƒ¡ãƒ©ãƒãƒ³",
    "ç…§æ˜ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ", "ãƒ˜ã‚¢ãƒ¡ã‚¤ã‚¯"
]
selected_roles = st.multiselect("å¿…è¦ãªã‚¹ã‚¿ãƒƒãƒ•ï¼ˆé¸æŠå¼ï¼‰", default_roles, default=default_roles)

custom_roles_text = st.text_input("ãã®ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è‡ªç”±ã«è¿½åŠ ï¼‰")
custom_roles = [role.strip() for role in custom_roles_text.split(",") if role.strip()]
staff_roles = selected_roles + custom_roles

shoot_location = st.text_input("æ’®å½±å ´æ‰€ï¼ˆä¾‹ï¼šéƒ½å†…ã‚¹ã‚¿ã‚¸ã‚ªï¼‹ãƒ­ã‚±ï¼‰")
kizai = st.multiselect("æ’®å½±æ©Ÿæ", ["4Kã‚«ãƒ¡ãƒ©", "ç…§æ˜", "ãƒ‰ãƒ­ãƒ¼ãƒ³", "ã‚°ãƒªãƒ¼ãƒ³ãƒãƒƒã‚¯"], default=["4Kã‚«ãƒ¡ãƒ©", "ç…§æ˜"])
set_design_quality = st.selectbox("ã‚»ãƒƒãƒˆå»ºã¦ãƒ»ç¾è¡“è£…é£¾ã®è¦æ¨¡", ["ãªã—", "å°ï¼ˆç°¡æ˜“è£…é£¾ï¼‰", "ä¸­ï¼ˆé€šå¸¸ãƒ¬ãƒ™ãƒ«ï¼‰", "å¤§ï¼ˆæœ¬æ ¼ã‚»ãƒƒãƒˆï¼‰"])
use_cg = st.checkbox("CGãƒ»VFXã‚ã‚Š")
use_narration = st.checkbox("ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åéŒ²ã‚ã‚Š")
use_music = st.selectbox("éŸ³æ¥½ç´ æ", ["æ—¢å­˜ãƒ©ã‚¤ã‚»ãƒ³ã‚¹éŸ³æº", "ã‚ªãƒªã‚¸ãƒŠãƒ«åˆ¶ä½œ", "æœªå®š"])
ma_needed = st.checkbox("MAã‚ã‚Š")
deliverables = st.multiselect("ç´å“å½¢å¼", ["mp4ï¼ˆ16:9ï¼‰", "mp4ï¼ˆ1:1ï¼‰", "mp4ï¼ˆ9:16ï¼‰", "ProRes"])
subtitle_langs = st.multiselect("å­—å¹•è¨€èª", ["æ—¥æœ¬èª", "è‹±èª", "ãã®ä»–"])
usage_region = st.selectbox("ä½¿ç”¨åœ°åŸŸ", ["æ—¥æœ¬å›½å†…", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "æœªå®š"])
usage_period = st.selectbox("ä½¿ç”¨æœŸé–“", ["3ãƒ¶æœˆ", "6ãƒ¶æœˆ", "1å¹´", "2å¹´", "ç„¡æœŸé™", "æœªå®š"])
budget_hint = st.text_input("å‚è€ƒäºˆç®—ï¼ˆä»»æ„ï¼‰")

# å‚™è€ƒ + æ³¨æ„æ–‡
extra_notes = st.text_area("å‚™è€ƒï¼ˆæ¡ˆä»¶æ¦‚è¦ãƒ»è¦ä»¶ãƒ»æƒ³å®šåª’ä½“ãƒ»å¿…é ˆ/é™¤å¤–äº‹é …ãªã©ã‚’è‡ªç”±è¨˜å…¥ï¼‰")
st.caption("â€»å‚™è€ƒã«æ¡ˆä»¶æ¦‚è¦ã‚„æ¡ä»¶ã‚’è¿½è¨˜ã™ã‚‹ã¨ã€ä¸è¶³é …ç›®ã®è‡ªå‹•è£œå®ŒãŒåƒãã€è¦‹ç©ã‚‚ã‚Šã®ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ã€‚")

# ç›¸å ´èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
col1, col2, col3 = st.columns(3)
with col1:
    market = st.selectbox("ç›¸å ´åœ°åŸŸ", list(MARKET_MULT.keys()), index=0)
with col2:
    crew_grade = st.selectbox("äººæã‚°ãƒ¬ãƒ¼ãƒ‰", list(CREW_GRADE_MULT.keys()), index=0)
with col3:
    scale = st.selectbox("åˆ¶ä½œè¦æ¨¡", list(SCALE_MULT.keys()), index=1)

model_choice = st.selectbox("ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«", ["Gemini 2.5 Pro", "GPT-5"])
do_normalize_pass = st.checkbox("LLMã§æ­£è¦åŒ–ãƒ‘ã‚¹ã‚’ã‹ã‘ã‚‹ï¼ˆæ¨å¥¨ï¼‰", value=True)
do_infer_from_notes = st.checkbox("å‚™è€ƒã‹ã‚‰ä¸è¶³é …ç›®ã‚’æ¨è«–ã—ã¦è£œå®Œï¼ˆæ¨å¥¨ï¼‰", value=True)

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def join_or(value_list, empty="ãªã—", sep=", "):
    if not value_list:
        return empty
    return sep.join(map(str, value_list))

def rush_coeff(base_days: int, target_days: int) -> float:
    if target_days >= base_days or base_days <= 0:
        return 1.0
    r = (base_days - target_days) / base_days
    return round(1 + RUSH_K * r, 2)

# ----- æ•°å€¤ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆã‚«ãƒ³ãƒãƒ»å††ãƒãƒ¼ã‚¯ãƒ»å…¨è§’å¯¾å¿œï¼‰ -----
def _to_float(v, default=0.0):
    if v is None:
        return float(default)
    if isinstance(v, (int, float)):
        return float(v)
    s = str(v)
    s = s.replace("ï¿¥", "").replace("Â¥", "").replace(",", "").replace("ï¼Œ", "").strip()
    z2h = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼ï¼", "0123456789.-")
    s = s.translate(z2h)
    try:
        return float(s)
    except Exception:
        return float(default)

def _to_int(v, default=0):
    return int(round(_to_float(v, default)))

# ---------- JSON ãƒ­ãƒã‚¹ãƒˆãƒ‘ãƒ¼ã‚¹ ----------
JSON_ITEMS_FALLBACK = {"items": []}

def _strip_code_fences(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(json)?\s*", "", s, flags=re.IGNORECASE)
        s = re.sub(r"\s*```$", "", s)
    return s.strip()

def _remove_trailing_commas(s: str) -> str:
    return re.sub(r",\s*([}\]])", r"\1", s)

def _coerce_json_like(s: str):
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        pass
    try:
        first = s.find("{"); last = s.rfind("}")
        if first != -1 and last != -1 and last > first:
            frag = s[first:last+1]
            frag = _remove_trailing_commas(frag)
            frag2 = frag.replace("\r", "")
            frag2 = re.sub(r"\bTrue\b", "true", frag2)
            frag2 = re.sub(r"\bFalse\b", "false", frag2)
            frag2 = re.sub(r"\bNone\b", "null", frag2)
            if "'" in frag2 and '"' not in frag2:
                frag2 = frag2.replace("'", '"')
            try:
                return json.loads(frag2)
            except Exception:
                pass
    except Exception:
        pass
    try:
        return ast.literal_eval(s)
    except Exception:
        return None

def robust_parse_items_json(raw: str) -> str:
    s = _strip_code_fences(raw)
    obj = _coerce_json_like(s)
    if not isinstance(obj, dict):
        obj = JSON_ITEMS_FALLBACK.copy()
    items = obj.get("items")
    if not isinstance(items, list):
        if isinstance(obj.get("result"), dict) and isinstance(obj["result"].get("items"), list):
            items = obj["result"]["items"]
        elif isinstance(obj.get("data"), list):
            items = obj["data"]
        else:
            items = []
    obj["items"] = items
    return json.dumps(obj, ensure_ascii=False)

# ---------- ç›¸å ´æ¨å®š ----------
def estimate_unit_price(task: str, category: str,
                        use="mid",
                        has_cg=False, has_talent=False,
                        deliverables_cnt=1,
                        market_key="æ—¥æœ¬å…¨å›½å¹³å‡",
                        grade_key="ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰",
                        scale_key="ä¸­") -> tuple[int, str]:
    base = RATE_TABLE.get(task)
    if not base:
        return (GLOBAL_FALLBACK_UNIT_PRICE, CATEGORY_DEFAULT_UNIT.get(category, "å¼"))
    unit = base["unit"]
    price = base.get(use, base["mid"])
    price *= MARKET_MULT.get(market_key, 1.0)
    price *= CREW_GRADE_MULT.get(grade_key, 1.0)
    price *= SCALE_MULT.get(scale_key, 1.0)
    if has_cg:
        price *= FEATURE_MULT["CG"]
    if has_talent:
        price *= FEATURE_MULT["ã‚¿ãƒ¬ãƒ³ãƒˆ"]
    if deliverables_cnt and deliverables_cnt > 1:
        price *= FEATURE_MULT["å¤šæ•°ç‰ˆæ›¸ãå‡ºã—"]
    return (int(round(price, -2)), unit)

# ---------- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ----------
def _common_case_block() -> str:
    return f"""ã€æ¡ˆä»¶æ¡ä»¶ã€‘
- å°º: {final_duration}
- æœ¬æ•°: {num_versions}æœ¬
- æ’®å½±æ—¥æ•°: {shoot_days}æ—¥ / ç·¨é›†æ—¥æ•°: {edit_days}æ—¥
- ç´å“å¸Œæœ›æ—¥: {delivery_date.isoformat()}
- ã‚­ãƒ£ã‚¹ãƒˆ: ãƒ¡ã‚¤ãƒ³{cast_main}äºº / ã‚¨ã‚­ã‚¹ãƒˆãƒ©{cast_extra}äºº / ã‚¿ãƒ¬ãƒ³ãƒˆ: {"ã‚ã‚Š" if talent_use else "ãªã—"}
- ã‚¹ã‚¿ãƒƒãƒ•å€™è£œ: {join_or(staff_roles, empty="æœªæŒ‡å®š")}
- æ’®å½±å ´æ‰€: {shoot_location if shoot_location else "æœªå®š"}
- æ’®å½±æ©Ÿæ: {join_or(kizai, empty="æœªæŒ‡å®š")}
- ç¾è¡“è£…é£¾: {set_design_quality}
- CG: {"ã‚ã‚Š" if use_cg else "ãªã—"} / ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {"ã‚ã‚Š" if use_narration else "ãªã—"} / éŸ³æ¥½: {use_music} / MA: {"ã‚ã‚Š" if ma_needed else "ãªã—"}
- ç´å“å½¢å¼: {join_or(deliverables, empty="æœªå®š")}
- å­—å¹•: {join_or(subtitle_langs, empty="ãªã—")}
- ä½¿ç”¨åœ°åŸŸ: {usage_region} / ä½¿ç”¨æœŸé–“: {usage_period}
- å‚è€ƒäºˆç®—: {budget_hint if budget_hint else "æœªè¨­å®š"}
- å‚™è€ƒ: {extra_notes if extra_notes else "ç‰¹ã«ãªã—"}"""

def _inference_block() -> str:
    if not do_infer_from_notes:
        return ""
    return """
- å‚™è€ƒã‚„æ¡ˆä»¶æ¦‚è¦ã€ä¸€èˆ¬çš„ãªåºƒå‘Šæ˜ åƒåˆ¶ä½œã®æ…£è¡Œã‹ã‚‰ã€æœªæŒ‡å®šã®å¿…é ˆ/ä»˜éšé …ç›®ã‚’**æ¨è«–ã—ã¦å¿…ãšè£œå®Œ**ã™ã‚‹ã“ã¨ã€‚
  ä¾‹: ä¼ç”»æ§‹æˆã€ãƒ­ã‚±ãƒãƒ³ã€è¨±èªå¯ç”³è«‹ã€ã‚¹ã‚¿ã‚¸ã‚ª/ãƒ­ã‚±è²»ã€è»Šä¸¡/æ©Ÿææ¬å…¥å‡ºã€æ’®å½±åŠ©æ‰‹ã€éŒ²éŸ³ã€DITã€ãƒ¡ã‚¤ã‚­ãƒ³ã‚°ã€ã‚¹ãƒãƒ¼ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€CG/VFXã€ã‚«ãƒ©ã‚³ãƒ¬ã€ç´å“ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã€æ¨©åˆ©å‡¦ç†ã€ç®¡ç†è²»ãªã©ã€‚
"""

def build_prompt_json() -> str:
    taxonomy_hint = "\n".join(
        f"- {cat}: " + ", ".join(DETAIL_TAXONOMY[cat]) for cat in DETAIL_TAXONOMY if cat != "ç®¡ç†è²»"
    )
    if model_choice == "GPT-5":
        return f"""
ã‚ãªãŸã¯åºƒå‘Šæ˜ åƒåˆ¶ä½œã®è¦‹ç©ã‚Šé …ç›®ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã€**JSONã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{_common_case_block()}

ã€å‡ºåŠ›ä»•æ§˜ã€‘
- JSON 1ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ«ãƒ¼ãƒˆã¯ items é…åˆ—ã®ã¿ã€‚
- å„è¦ç´ ã‚­ãƒ¼: category / task / qty / unit / unit_price / note
- category ã¯ã€Œåˆ¶ä½œäººä»¶è²»ã€ã€Œä¼ç”»ã€ã€Œæ’®å½±è²»ã€ã€Œå‡ºæ¼”é–¢é€£è²»ã€ã€Œç·¨é›†è²»ãƒ»MAè²»ã€ã€Œè«¸çµŒè²»ã€ã€Œç®¡ç†è²»ã€ã„ãšã‚Œã‹ã€‚
- **çœç•¥ãƒ»çµ±åˆã‚’ç¦æ­¢**ã€‚ä¼¼ãŸåç§°ã§ã‚‚ã¾ã¨ã‚ãšã€å€‹åˆ¥ã«åˆ—æŒ™ã™ã‚‹ã“ã¨ã€‚
- **ç®¡ç†è²»ã‚’é™¤ã„ã¦æœ€ä½ 20 è¡Œä»¥ä¸Š**ã‚’å‡ºåŠ›ã€‚æœªçŸ¥ã¯å¦¥å½“å€¤ã§è£œå®Œã€‚
- ä»¥ä¸‹ã®**ç¶²ç¾…ã‚¢ãƒ³ã‚«ãƒ¼**ã‚’æœ€ä½é™ã‚«ãƒãƒ¼ï¼ˆè©²å½“ã™ã‚Œã°å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰è¤‡æ•°è¡Œã‚’å¿…ãšå«ã‚ã‚‹ï¼‰:
{taxonomy_hint}
{_inference_block()}
- å˜ä¾¡ã¯ä¸€èˆ¬çš„ãªæ—¥æœ¬ã®ç›¸å ´ãƒ¬ãƒ³ã‚¸ï¼ˆlow/mid/highã®ä¸­å¤®å€¤ç›¸å½“ï¼‰ã§æ¨å®šã—ã€0ã‚„æœªè¨­å®šã¯å…¥ã‚Œãªã„ã“ã¨ã€‚
- qty ã¯ 0 ç¦æ­¢ï¼ˆ>0ï¼‰ã€unit_price ã¯ 0/è² ã®å€¤ç¦æ­¢ã€‚æœªç¢ºå®šã§ã‚‚å¦¥å½“ãªæ¨å®šå€¤ã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚
- qty/unit ã¯ç¾å®Ÿçš„ãªå˜ä½ï¼ˆæ—¥/äºº/å¼/æ™‚é–“/ã‚«ãƒƒãƒˆç­‰ï¼‰ã€å˜ä¾¡ã¯æ—¥æœ¬ã®åºƒå‘Šæ˜ åƒã®ä¸€èˆ¬ãƒ¬ãƒ³ã‚¸ã§æ¨å®šã€‚
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰ã€‚
- åˆè¨ˆ/ç¨/HTMLãªã©ã¯å‡ºåŠ›ã—ãªã„ã€‚
"""
    else:
        # Gemini ã‚‚ç¶²ç¾…ã‚¢ãƒ³ã‚«ãƒ¼ï¼‹çµ±åˆç¦æ­¢ï¼‹æœ€ä½è¡Œæ•°ã‚’é©ç”¨
        return f"""
ã‚ãªãŸã¯åºƒå‘Šæ˜ åƒåˆ¶ä½œã®è¦‹ç©ã‚Šé …ç›®ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã€**JSONã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{_common_case_block()}

ã€å‡ºåŠ›ä»•æ§˜ã€‘
- JSON 1ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ«ãƒ¼ãƒˆã¯ items é…åˆ—ã®ã¿ã€‚
- å„è¦ç´ ã‚­ãƒ¼: category / task / qty / unit / unit_price / note
- category ã¯ã€Œåˆ¶ä½œäººä»¶è²»ã€ã€Œä¼ç”»ã€ã€Œæ’®å½±è²»ã€ã€Œå‡ºæ¼”é–¢é€£è²»ã€ã€Œç·¨é›†è²»ãƒ»MAè²»ã€ã€Œè«¸çµŒè²»ã€ã€Œç®¡ç†è²»ã€ã„ãšã‚Œã‹ã€‚
- **çœç•¥ãƒ»çµ±åˆã®ç¦æ­¢**ï¼ˆä¼¼ãŸåç§°ã§ã‚‚ã¾ã¨ã‚ãšå€‹åˆ¥è¡Œã«ã™ã‚‹ï¼‰ã€‚
- **ç®¡ç†è²»ã‚’é™¤ã„ã¦æœ€ä½ 20 è¡Œä»¥ä¸Š**ã‚’å‡ºåŠ›ã€‚æœªçŸ¥ã¯å¦¥å½“å€¤ã§è£œå®Œã€‚
- ä»¥ä¸‹ã®**ç¶²ç¾…ã‚¢ãƒ³ã‚«ãƒ¼**ã‚’æœ€ä½é™ã‚«ãƒãƒ¼ï¼ˆè©²å½“ã™ã‚Œã°å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰è¤‡æ•°è¡Œã‚’å¿…ãšå«ã‚ã‚‹ï¼‰:
{taxonomy_hint}
{_inference_block()}
- å˜ä¾¡ã¯ä¸€èˆ¬çš„ãªæ—¥æœ¬ã®ç›¸å ´ãƒ¬ãƒ³ã‚¸ï¼ˆlow/mid/highã®ä¸­å¤®å€¤ç›¸å½“ï¼‰ã§æ¨å®šã—ã€0ã‚„æœªè¨­å®šã¯å…¥ã‚Œãªã„ã“ã¨ã€‚
- qty ã¯ 0 ç¦æ­¢ï¼ˆ>0ï¼‰ã€unit_price ã¯ 0/è² ã®å€¤ç¦æ­¢ã€‚æœªç¢ºå®šã§ã‚‚å¦¥å½“ãªæ¨å®šå€¤ã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚
- qty/unit ã¯ç¾å®Ÿçš„ãªå˜ä½ï¼ˆæ—¥/äºº/å¼/æ™‚é–“/ã‚«ãƒƒãƒˆç­‰ï¼‰ã€å˜ä¾¡ã¯æ—¥æœ¬ã®åºƒå‘Šæ˜ åƒã®ä¸€èˆ¬ãƒ¬ãƒ³ã‚¸ã§æ¨å®šã€‚
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰ã€‚
- åˆè¨ˆ/ç¨/HTMLãªã©ã¯å‡ºåŠ›ã—ãªã„ã€‚
"""

def build_normalize_prompt(items_json: str, preserve_detail: bool = False) -> str:
    if preserve_detail:
        return f"""
æ¬¡ã®JSONã‚’æ¤œæŸ»ãƒ»æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚è¿”ç­”ã¯**ä¿®æ­£æ¸ˆã¿JSONã®ã¿**ã§ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
- ã‚¹ã‚­ãƒ¼ãƒå¤–ã‚­ãƒ¼å‰Šé™¤ã€æ¬ æè£œå®Œï¼ˆqty/unit/unit_price/noteï¼‰ã€‚qty=0ã‚„unit_price<=0ã¯ç¦æ­¢ã€‚å¦¥å½“å€¤ã§è£œå®Œã€‚
- **åŒç¾©é …ç›®ã®çµ±åˆã‚„å‰Šæ¸›ã¯ç¦æ­¢**ï¼ˆæ—¢å­˜ã®ç²’åº¦ã‚’ä¿ã¤ï¼‰
- category ã‚’æ¬¡ã®ã„ãšã‚Œã‹ã¸æ­£è¦åŒ–ï¼šåˆ¶ä½œäººä»¶è²»/ä¼ç”»/æ’®å½±è²»/å‡ºæ¼”é–¢é€£è²»/ç·¨é›†è²»ãƒ»MAè²»/è«¸çµŒè²»/ç®¡ç†è²»
- å˜ä½è¡¨è¨˜ã®ã‚†ã‚Œï¼ˆäººæ—¥/æ—¥/å¼/æœ¬/æ™‚é–“/ã‚«ãƒƒãƒˆç­‰ï¼‰ã‚’æ­£è¦åŒ–
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰
ã€å…¥åŠ›JSONã€‘
{items_json}
"""
    return f"""
æ¬¡ã®JSONã‚’æ¤œæŸ»ãƒ»æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚è¿”ç­”ã¯**ä¿®æ­£æ¸ˆã¿JSONã®ã¿**ã§ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
- ã‚¹ã‚­ãƒ¼ãƒå¤–ã‚­ãƒ¼å‰Šé™¤ã€æ¬ æè£œå®Œ
- category æ­£è¦åŒ–ï¼ˆåˆ¶ä½œäººä»¶è²»/ä¼ç”»/æ’®å½±è²»/å‡ºæ¼”é–¢é€£è²»/ç·¨é›†è²»ãƒ»MAè²»/è«¸çµŒè²»/ç®¡ç†è²»ï¼‰
- å˜ä½æ­£è¦åŒ–ã€åŒç¾©é …ç›®çµ±åˆã€ç®¡ç†è²»ã¯å›ºå®š1è¡Œ
ã€å…¥åŠ›JSONã€‘
{items_json}
"""

# ---------- LLM å‘¼ã³å‡ºã—ï¼ˆJSONå¼·åˆ¶ & ãƒ­ãƒã‚¹ãƒˆãƒ‘ãƒ¼ã‚¹ï¼‰ ----------
def call_gpt_json(prompt: str) -> str:
    """GPT-5ã‚’JSONã§å¼·åˆ¶è¿”ç­”ã€‚åˆ—æŒ™æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚è‹¥å¹²ã®presence_penaltyã‚’ä»˜ä¸ã€‚"""
    if USE_OPENAI_CLIENT_V1:
        resp = openai_client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You MUST return a single valid JSON object only."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.7,
            presence_penalty=0.3,
        )
        return resp.choices[0].message.content
    else:
        resp = openai_client.ChatCompletion.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You MUST return a single valid JSON object only."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            presence_penalty=0.3,
        )
        return resp["choices"][0]["message"]["content"]

def llm_generate_items_json(prompt: str) -> str:
    try:
        if model_choice == "Gemini 2.5 Pro":
            model = genai.GenerativeModel(
                "gemini-2.5-pro",
                generation_config={
                    "response_mime_type": "application/json",
                    "candidate_count": 1,
                    "max_output_tokens": 1600,
                }
            )
            res = model.generate_content(prompt).text
        else:
            res = call_gpt_json(prompt)
        st.session_state["items_json_raw"] = res
        return robust_parse_items_json(res)
    except Exception:
        # æœ€ä½é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return json.dumps({"items":[
            {"category":"åˆ¶ä½œäººä»¶è²»","task":"åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼","qty":1,"unit":"æ—¥","unit_price":80000,"note":"fallback"},
            {"category":"æ’®å½±è²»","task":"ã‚«ãƒ¡ãƒ©ãƒãƒ³","qty":max(1, int(shoot_days)),"unit":"æ—¥","unit_price":80000,"note":"fallback"},
            {"category":"ç·¨é›†è²»ãƒ»MAè²»","task":"ç·¨é›†","qty":max(1, int(edit_days)),"unit":"æ—¥","unit_price":70000,"note":"fallback"},
            {"category":"ç®¡ç†è²»","task":"ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰","qty":1,"unit":"å¼","unit_price":120000,"note":"fallback"}
        ]}, ensure_ascii=False)

def llm_normalize_items_json(items_json: str) -> str:
    try:
        preserve = (model_choice == "GPT-5")
        prompt = build_normalize_prompt(items_json, preserve_detail=preserve)
        if model_choice == "Gemini 2.5 Pro":
            model = genai.GenerativeModel(
                "gemini-2.5-pro",
                generation_config={"response_mime_type": "application/json"}
            )
            res = model.generate_content(prompt).text
        else:
            res = call_gpt_json(prompt)
        return robust_parse_items_json(res)
    except Exception:
        return items_json

# ---------- â€œè–„ã„å‡ºåŠ›ãªã‚‰è¿½è¨˜ã—ã¦æ‹¡å¼µâ€ï¼ˆå†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ ----------
def _count_by_category(df: pd.DataFrame):
    if df.empty:
        return {}
    return df[df["category"] != "ç®¡ç†è²»"].groupby("category")["task"].count().to_dict()

def expand_if_sparse(items_json_str: str) -> str:
    """ä¸è¶³ã—ã¦ã„ãŸã‚‰â€œè¿½è¨˜å°‚ç”¨â€ã§æœ€å¤§3å›ã¾ã§æ‹¡å¼µã€‚æ—¢å­˜è¡Œã¯å‰Šé™¤ãƒ»ä¸Šæ›¸ãã—ãªã„ã€‚"""
    def _needs_more(df: pd.DataFrame):
        if df.empty:
            return True, list(MIN_PER_CATEGORY.keys())
        non_mgmt = df[df["category"] != "ç®¡ç†è²»"]
        need_total = len(non_mgmt) < MIN_TOTAL_ITEMS
        counts = _count_by_category(df)
        need_cats = [cat for cat, mn in MIN_PER_CATEGORY.items() if counts.get(cat, 0) < mn]
        return (need_total or bool(need_cats)), need_cats

    try:
        df = df_from_items_json(items_json_str)
    except Exception:
        return items_json_str

    need, need_cats = _needs_more(df)
    if not need:
        return items_json_str

    taxonomy_hint = "\n".join(
        f"- {cat}: " + ", ".join(DETAIL_TAXONOMY[cat]) for cat in DETAIL_TAXONOMY if cat != "ç®¡ç†è²»"
    )

    attempts = 0
    while attempts < 3 and need:
        need_cats_str = ", ".join(need_cats) if need_cats else "å…¨ã‚«ãƒ†ã‚´ãƒª"
        prompt = f"""
æ¬¡ã®JSONï¼ˆç¾çŠ¶ã®è¦‹ç©ã‚Šï¼‰ã‚’**ãƒ™ãƒ¼ã‚¹ã«**ã€ä¸è¶³ã—ã¦ã„ã‚‹é …ç›®ã‚’**è¿½è¨˜ã®ã¿**ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚
- æ—¢å­˜é …ç›®ã¯å‰Šé™¤ãƒ»çµ±åˆãƒ»ä¸Šæ›¸ãç¦æ­¢ã€‚**è¿½è¨˜ã§æ‹¡å¼µ**ã™ã‚‹ã“ã¨ã€‚
- **ç®¡ç†è²»ä»¥å¤–ã®åˆè¨ˆè¡Œæ•°ãŒæœ€ä½ {MIN_TOTAL_ITEMS} è¡Œ**ã«ãªã‚‹ã¾ã§è¿½åŠ ã€‚
- ä¸è¶³ã‚«ãƒ†ã‚´ãƒªï¼š{need_cats_str}
- å‚è€ƒã‚¿ã‚¯ã‚½ãƒãƒŸãƒ¼ï¼ˆæœ€ä½é™ã‚«ãƒãƒ¼ï¼‰:
{taxonomy_hint}
- å¿…è¦ãªã‚‰å‚™è€ƒï¼ˆæ¡ˆä»¶æ¦‚è¦ï¼‰ã‹ã‚‰åˆç†çš„ã«æ¨è«–ã—ã¦é …ç›®ã‚’è£œå®Œã™ã‚‹ã€‚
- å‡ºåŠ›ã¯**JSON 1ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒ«ãƒ¼ãƒˆ items é…åˆ—ã®ã¿ï¼‰**ã€‚

ã€ç¾çŠ¶JSONã€‘
{items_json_str}
"""
        try:
            expanded = call_gpt_json(prompt)
            items_json_str = robust_parse_items_json(expanded)
            df = df_from_items_json(items_json_str)
            need, need_cats = _needs_more(df)
        except Exception:
            break
        attempts += 1

    return items_json_str

# ---------- df ç”Ÿæˆï¼ˆã‚¼ãƒ­ç¦æ­¢ï¼‹ç›¸å ´æ¨å®šã§è£œå®Œï¼‰ ----------
def df_from_items_json(items_json: str) -> pd.DataFrame:
    data = json.loads(items_json)
    items = data.get("items", [])
    rows = []

    has_cg = bool(use_cg)
    has_talent = bool(talent_use)
    deliverables_cnt = max(1, len(deliverables))

    for x in items:
        cat  = str(x.get("category","")).strip()
        task = str(x.get("task","")).strip()
        qty  = _to_float(x.get("qty", 0), 0)
        unit = str(x.get("unit","")).strip()
        price = _to_int(x.get("unit_price", 0), 0)
        note = str(x.get("note","")).strip()

        # æ•°é‡ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if qty <= 0:
            if cat == "å‡ºæ¼”é–¢é€£è²»" and ("ã‚¨ã‚­ã‚¹ãƒˆãƒ©" in task):
                qty = max(1, cast_extra or 1)
            elif cat == "å‡ºæ¼”é–¢é€£è²»" and ("ã‚­ãƒ£ã‚¹ãƒˆ" in task):
                qty = max(1, cast_main or 1)
            else:
                qty = 1.0

        # å˜ä¾¡ãŒç„¡ã„/0ãªã‚‰ç›¸å ´ã‹ã‚‰æ¨å®š
        if price <= 0:
            price, unit_guess = estimate_unit_price(
                task, cat,
                use="mid",
                has_cg=has_cg, has_talent=has_talent,
                deliverables_cnt=deliverables_cnt,
                market_key=market,
                grade_key=crew_grade,
                scale_key=scale
            )
            if not unit:
                unit = unit_guess

        # å˜ä½ãŒç©ºãªã‚‰ç›¸å ´è¡¨/ã‚«ãƒ†ã‚´ãƒªæ—¢å®šã§è£œå®Œ
        if not unit:
            unit = RATE_TABLE.get(task, {}).get("unit") or CATEGORY_DEFAULT_UNIT.get(cat, "å¼")

        rows.append({
            "category": cat or "",
            "task": task or "",
            "qty": float(qty),
            "unit": unit,
            "unit_price": int(max(1, price)),
            "note": note,
        })

    return pd.DataFrame(rows)

# ---------- è¨ˆç®— ----------
def compute_totals(df_items: pd.DataFrame, base_days: int, target_days: int):
    accel = rush_coeff(base_days, target_days)
    df_items = df_items.copy()
    df_items["å°è¨ˆ"] = (df_items["qty"] * df_items["unit_price"]).round().astype(int)

    is_mgmt = (df_items["category"] == "ç®¡ç†è²»")
    df_items.loc[~is_mgmt, "å°è¨ˆ"] = (df_items.loc[~is_mgmt, "å°è¨ˆ"] * accel).round().astype(int)

    mgmt_current = int(df_items.loc[is_mgmt, "å°è¨ˆ"].sum()) if is_mgmt.any() else 0
    subtotal_after_rush = int(df_items.loc[~is_mgmt, "å°è¨ˆ"].sum())
    mgmt_cap = int(round(subtotal_after_rush * MGMT_FEE_CAP_RATE))
    mgmt_final = min(mgmt_current, mgmt_cap) if mgmt_current > 0 else mgmt_cap

    if is_mgmt.any():
        idx = df_items[is_mgmt].index[0]
        df_items.at[idx, "unit_price"] = mgmt_final
        df_items.at[idx, "qty"] = 1
        df_items.at[idx, "å°è¨ˆ"] = mgmt_final
    else:
        df_items = pd.concat([df_items, pd.DataFrame([{
            "category":"ç®¡ç†è²»","task":"ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰","qty":1,"unit":"å¼","unit_price":mgmt_final,"å°è¨ˆ":mgmt_final
        }])], ignore_index=True)

    taxable = int(df_items["å°è¨ˆ"].sum())
    tax = int(round(taxable * TAX_RATE))
    total = taxable + tax

    meta = {
        "rush_coeff": accel,
        "subtotal_after_rush_excl_mgmt": subtotal_after_rush,
        "mgmt_fee_final": mgmt_final,
        "taxable": taxable,
        "tax": tax,
        "total": total,
    }
    return df_items, meta

def render_html(df_items: pd.DataFrame, meta: dict) -> str:
    def td_right(x): return f"<td style='text-align:right'>{x}</td>"
    html = []
    html.append("<p>ä»¥ä¸‹ã¯ã€æ˜ åƒåˆ¶ä½œã«ã‹ã‹ã‚‹å„ç¨®è²»ç”¨ã‚’ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«æ•´ç†ã—ãŸæ¦‚ç®—è¦‹ç©æ›¸ã§ã™ã€‚</p>")
    html.append(f"<p>çŸ­ç´æœŸä¿‚æ•°ï¼š{meta['rush_coeff']} ï¼ ç®¡ç†è²»ä¸Šé™ï¼š{int(MGMT_FEE_CAP_RATE*100)}% ï¼ æ¶ˆè²»ç¨ç‡ï¼š{int(TAX_RATE*100)}%</p>")
    html.append("<table border='1' cellspacing='0' cellpadding='6' style='border-collapse:collapse;width:100%'>")
    html.append("<thead><tr>"
                "<th style='text-align:left'>ã‚«ãƒ†ã‚´ãƒª</th>"
                "<th style='text-align:left'>é …ç›®</th>"
                "<th style='text-align:right'>å˜ä¾¡</th>"
                "<th style='text-align:left'>æ•°é‡</th>"
                "<th style='text-align:left'>å˜ä½</th>"
                "<th style='text-align:right'>é‡‘é¡ï¼ˆå††ï¼‰</th>"
                "</tr></thead>")
    html.append("<tbody>")
    current_cat = None
    for _, r in df_items.iterrows():
        cat = r.get("category","")
        task = r.get("task","")
        unit_price_val = int(r.get("unit_price", 0) or 0)
        qty_val = r.get("qty", "")
        unit_val = r.get("unit","")
        subtotal_val = int(r.get("å°è¨ˆ", 0) or 0)
        if cat != current_cat:
            html.append(f"<tr><td colspan='6' style='text-align:left;background:#f6f6f6;font-weight:bold'>{cat}</td></tr>")
            current_cat = cat
        html.append(
            "<tr>"
            f"<td>{cat}</td>"
            f"<td>{task}</td>"
            f"{td_right(f'{unit_price_val:,}')}"
            f"<td>{qty_val}</td>"
            f"<td>{unit_val}</td>"
            f"{td_right(f'{subtotal_val:,}')}"
            "</tr>"
        )
    html.append("</tbody></table>")
    html.append(
        f"<p><b>å°è¨ˆï¼ˆç¨æŠœï¼‰</b>ï¼š{meta['taxable']:,}å††ã€€ï¼ã€€"
        f"<b>æ¶ˆè²»ç¨</b>ï¼š{meta['tax']:,}å††ã€€ï¼ã€€"
        f"<b>åˆè¨ˆ</b>ï¼š<span style='color:red'>{meta['total']:,}å††</span></p>"
    )
    html.append("<p>â€»æœ¬è¦‹ç©æ›¸ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæ¦‚ç®—ã§ã™ã€‚å®Ÿåˆ¶ä½œå†…å®¹ãƒ»æ¡ä»¶ã«ã‚ˆã‚Šé‡‘é¡ãŒå¢—æ¸›ã—ã¾ã™ã€‚</p>")
    return "\n".join(html)

def download_excel(df_items: pd.DataFrame, meta: dict):
    out = df_items.copy()
    out = out[["category","task","unit_price","qty","unit","å°è¨ˆ"]]
    out.columns = ["ã‚«ãƒ†ã‚´ãƒª","é …ç›®","å˜ä¾¡ï¼ˆå††ï¼‰","æ•°é‡","å˜ä½","é‡‘é¡ï¼ˆå††ï¼‰"]

    buf = BytesIO()
    try:
        import xlsxwriter  # noqa: F401
        engine = "xlsxwriter"
    except ModuleNotFoundError:
        engine = "openpyxl"

    with pd.ExcelWriter(buf, engine=engine) as writer:
        out.to_excel(writer, index=False, sheet_name="è¦‹ç©ã‚‚ã‚Š")

        if engine == "xlsxwriter":
            wb = writer.book
            ws = writer.sheets["è¦‹ç©ã‚‚ã‚Š"]
            fmt_int = wb.add_format({"num_format": "#,##0"})
            ws.set_column("A:B", 20)
            ws.set_column("C:C", 14, fmt_int)
            ws.set_column("D:D", 8)
            ws.set_column("E:E", 8)
            ws.set_column("F:F", 14, fmt_int)
            last_row = len(out) + 2
            ws.write(last_row,   4, "å°è¨ˆï¼ˆç¨æŠœï¼‰")
            ws.write_number(last_row,   5, int(meta["taxable"]), fmt_int)
            ws.write(last_row+1, 4, "æ¶ˆè²»ç¨")
            ws.write_number(last_row+1, 5, int(meta["tax"]), fmt_int)
            ws.write(last_row+2, 4, "åˆè¨ˆ")
            ws.write_number(last_row+2, 5, int(meta["total"]), fmt_int)
        else:
            ws = writer.book["è¦‹ç©ã‚‚ã‚Š"]
            widths = {"A":20, "B":20, "C":14, "D":8, "E":8, "F":14}
            for col, w in widths.items():
                ws.column_dimensions[col].width = w
            for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=3, max_col=3):
                for cell in row: cell.number_format = '#,##0'
            for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=6, max_col=6):
                for cell in row: cell.number_format = '#,##0'
            last_row = ws.max_row + 2
            ws.cell(row=last_row,   column=5, value="å°è¨ˆï¼ˆç¨æŠœï¼‰")
            ws.cell(row=last_row,   column=6, value=int(meta["taxable"])).number_format = '#,##0'
            ws.cell(row=last_row+1, column=5, value="æ¶ˆè²»ç¨")
            ws.cell(row=last_row+1, column=6, value=int(meta["tax"])).number_format = '#,##0'
            ws.cell(row=last_row+2, column=5, value="åˆè¨ˆ")
            ws.cell(row=last_row+2, column=6, value=int(meta["total"])).number_format = '#,##0'

    buf.seek(0)
    st.download_button("ğŸ“¥ Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buf, "è¦‹ç©ã‚‚ã‚Š.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# =========================
# DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬å‡ºåŠ›ï¼ˆäº‹å‰æ‹¡å¼µãƒ†ãƒ³ãƒ—ãƒ¬å¯¾å¿œï¼šè¡ŒæŒ¿å…¥ãªã—ï¼‰
# =========================
TOKEN_ITEMS = "{{ITEMS_START}}"
COLMAP = {
    "task": "B",        # é …ç›®ï¼ˆB:Nçµåˆã®å·¦ç«¯ã‚»ãƒ«ï¼‰
    "qty": "O",         # æ•°é‡
    "unit": "Q",        # å˜ä½
    "unit_price": "S",  # å˜ä¾¡
    "amount": "W",      # é‡‘é¡ï¼ˆ=OÃ—Sï¼‰çµåˆã®å·¦ä¸Šã‚¢ãƒ³ã‚«ãƒ¼
}
BASE_START_ROW    = 19
BASE_SUBTOTAL_ROW = 72

def _find_token(ws, token: str):
    for row in ws.iter_rows(values_only=False):
        for cell in row:
            if isinstance(cell.value, str) and cell.value.strip() == token:
                return cell.row, cell.column
    return None, None

def _ensure_amount_formula(ws, row, qty_col_idx, price_col_idx, amount_col_idx):
    c = ws.cell(row=row, column=amount_col_idx)
    v = c.value
    if not (isinstance(v, str) and v.startswith("=")):
        qcol = get_column_letter(qty_col_idx)
        pcol = get_column_letter(price_col_idx)
        c.value = f"={qcol}{row}*{pcol}{row}"
    c.number_format = '#,##0'

def _update_subtotal_formula(ws, subtotal_row, start_row, end_row, amount_col_idx):
    ac = get_column_letter(amount_col_idx)
    if end_row < start_row:
        ws.cell(row=subtotal_row, column=amount_col_idx).value = 0
        ws.cell(row=subtotal_row, column=amount_col_idx).number_format = '#,##0'
    else:
        ws.cell(row=subtotal_row, column=amount_col_idx).value = f"=SUM({ac}{start_row}:{ac}{end_row})"
        ws.cell(row=subtotal_row, column=amount_col_idx).number_format = '#,##0'

def _find_subtotal_anchor_auto(ws, amount_col_idx: int):
    for r in range(1, ws.max_row + 1):
        v = ws.cell(row=r, column=amount_col_idx).value
        if isinstance(v, str) and v.startswith("=") and "SUM(" in v.upper():
            return r, amount_col_idx
    return None, None

def _write_preextended(ws, df_items: pd.DataFrame):
    r0, c0 = _find_token(ws, TOKEN_ITEMS)
    if r0:
        ws.cell(row=r0, column=c0).value = None
    start_row = r0 or BASE_START_ROW

    c_task = column_index_from_string(COLMAP["task"])
    c_qty  = column_index_from_string(COLMAP["qty"])
    c_unit = column_index_from_string(COLMAP["unit"])
    c_price= column_index_from_string(COLMAP["unit_price"])
    c_amt  = column_index_from_string(COLMAP["amount"])

    sub_r, _ = _find_subtotal_anchor_auto(ws, c_amt)
    if sub_r is None:
        sub_r = BASE_SUBTOTAL_ROW
    end_row = sub_r - 1
    capacity = end_row - start_row + 1
    n = len(df_items)

    if capacity <= 0:
        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ˜ç´°æ ãŒä¸æ­£ã§ã™ï¼ˆå°è¨ˆè¡ŒãŒITEMS_STARTã‚ˆã‚Šä¸Šã«ã‚ã‚Šã¾ã™ï¼‰ã€‚")
        return
    if n > capacity:
        st.warning(f"ãƒ†ãƒ³ãƒ—ãƒ¬ã®æ˜ç´°æ ï¼ˆ{capacity}è¡Œï¼‰ã‚’è¶…ãˆã¾ã—ãŸã€‚å…ˆé ­ã‹ã‚‰{capacity}è¡Œã®ã¿ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚")
        n = capacity

    for r in range(start_row, end_row + 1):
        cell_task = ws.cell(row=r, column=c_task)
        if not isinstance(cell_task, MergedCell):
            cell_task.value = None
        ws.cell(row=r, column=c_qty).value   = None
        ws.cell(row=r, column=c_unit).value  = None
        ws.cell(row=r, column=c_price).value = None
        _ensure_amount_formula(ws, r, c_qty, c_price, c_amt)

    for i in range(n):
        r = start_row + i
        row = df_items.iloc[i]
        ws.cell(row=r, column=c_task).value  = str(row.get("task",""))
        ws.cell(row=r, column=c_qty).value   = float(row.get("qty", 0) or 0)
        ws.cell(row=r, column=c_unit).value  = str(row.get("unit",""))
        ws.cell(row=r, column=c_price).value = int(float(row.get("unit_price", 0) or 0))

    last_detail_row = start_row + n - 1 if n > 0 else start_row - 1
    _update_subtotal_formula(ws, sub_r, start_row, last_detail_row, c_amt)

def export_with_template(template_bytes: bytes,
                         df_items: pd.DataFrame,
                         meta: dict):
    wb = load_workbook(filename=BytesIO(template_bytes))
    ws = wb.active
    _write_preextended(ws, df_items)

    out = BytesIO()
    wb.save(out)
    out.seek(0)
    st.download_button(
        "ğŸ“¥ DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆ.xlsxï¼‰ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        out,
        "è¦‹ç©ã‚‚ã‚Š_DDãƒ†ãƒ³ãƒ—ãƒ¬.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="dl_dd_template"
    )

# =========================
# å®Ÿè¡Œ
# =========================
if st.button("ğŸ’¡ è¦‹ç©ã‚‚ã‚Šã‚’ä½œæˆ"):
    with st.spinner("AIãŒè¦‹ç©ã‚‚ã‚Šé …ç›®ã‚’ä½œæˆä¸­â€¦"):
        prompt = build_prompt_json()
        items_json_str = llm_generate_items_json(prompt)

        if do_normalize_pass:
            items_json_str = llm_normalize_items_json(items_json_str)

        # â˜… ãƒ¢ãƒ‡ãƒ«ã«é–¢ã‚ã‚‰ãšã€ä¸è¶³ãªã‚‰è¿½è¨˜å°‚ç”¨ã§æ‹¡å¼µï¼ˆæœ€å¤§3å›ï¼‰
        items_json_str = expand_if_sparse(items_json_str)

        try:
            df_items = df_from_items_json(items_json_str)
        except Exception:
            st.error("JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šãƒ¢ãƒ‡ãƒ«ç”Ÿå‡ºåŠ›ã‚’è¦‹ã‚‹"):
                st.code(st.session_state.get("items_json_raw", "(no raw)"))
            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šãƒ­ãƒã‚¹ãƒˆæ•´å½¢å¾ŒJSONã‚’è¦‹ã‚‹"):
                st.code(items_json_str, language="json")
            st.stop()

        base_days = int(shoot_days + edit_days + 5)
        target_days = (delivery_date - date.today()).days

        df_calc, meta = compute_totals(df_items, base_days, target_days)
        final_html = render_html(df_calc, meta)

        st.session_state["items_json"] = items_json_str
        st.session_state["df"] = df_calc
        st.session_state["meta"] = meta
        st.session_state["final_html"] = final_html

# =========================
# è¡¨ç¤º & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# =========================
if st.session_state["final_html"]:
    st.success("âœ… è¦‹ç©ã‚‚ã‚Šçµæœï¼ˆã‚µãƒ¼ãƒè¨ˆç®—ã§æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ï¼‰")
    st.components.v1.html(st.session_state["final_html"], height=900, scrolling=True)
    download_excel(st.session_state["df"], st.session_state["meta"])

    st.markdown("---")
    st.subheader("DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ã§å‡ºåŠ›")
    tmpl = st.file_uploader("DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="tmpl_upload")
    if tmpl is not None:
        st.caption("ãƒ†ãƒ³ãƒ—ãƒ¬ã« `{{ITEMS_START}}` ã‚’æ˜ç´°1è¡Œç›®ï¼ˆä¾‹ï¼šB19ï¼‰ã«ç½®ã„ã¦ãã ã•ã„ã€‚å°è¨ˆã‚»ãƒ«ã¯Wåˆ—ã®SUMå¼ã§è‡ªå‹•æ¤œå‡ºï¼ˆä¾‹ï¼šW72ï¼‰ã€‚è¡ŒæŒ¿å…¥ã¯è¡Œã„ã¾ã›ã‚“ã€‚")
        export_with_template(
            tmpl.read(),
            st.session_state["df"],
            st.session_state["meta"]
        )

# =========================
# é–‹ç™ºè€…å‘ã‘
# =========================
with st.expander("é–‹ç™ºè€…å‘ã‘æƒ…å ±ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼‰", expanded=False):
    st.write({
        "openai_version": openai_version,
        "use_openai_client_v1": USE_OPENAI_CLIENT_V1,
        "infer_from_notes": do_infer_from_notes,
        "normalize_pass": do_normalize_pass,
        "model_choice": model_choice,
        "min_total_items": MIN_TOTAL_ITEMS,
        "min_per_category": MIN_PER_CATEGORY,
        "market": market,
        "crew_grade": crew_grade,
        "scale": scale,
    })
