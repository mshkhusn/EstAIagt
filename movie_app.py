# app.py
import os
import re
import json
import importlib
from io import BytesIO
from datetime import date
import ast

import streamlit as st
import pandas as pd
import google.generativeai as genai
from dateutil.relativedelta import relativedelta

# ===== openpyxl / Excel =====
from openpyxl import load_workbook
from openpyxl.cell.cell import MergedCell
from openpyxl.utils import column_index_from_string, get_column_letter

# =========================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =========================
st.set_page_config(page_title="æ˜ åƒåˆ¶ä½œæ¦‚ç®—è¦‹ç©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ vNext", layout="centered")

# =========================
# Secrets
# =========================
GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
APP_PASSWORD   = st.secrets["APP_PASSWORD"]

genai.configure(api_key=GEMINI_API_KEY)
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# =========================
# OpenAI åˆæœŸåŒ–ï¼ˆv1/v0 ä¸¡å¯¾å¿œï¼‰
# =========================
USE_OPENAI_CLIENT_V1 = False
openai_client = None
openai_version = "unknown"
try:
    from openai import OpenAI as _OpenAI
    openai_client = _OpenAI()
    USE_OPENAI_CLIENT_V1 = True
    try:
        mod = importlib.import_module("openai")
        openai_version = getattr(mod, "__version__", "1.x")
    except Exception:
        openai_version = "1.x"
except Exception:
    import openai as _openai
    _openai.api_key = OPENAI_API_KEY
    openai_client = _openai
    USE_OPENAI_CLIENT_V1 = False
    openai_version = getattr(openai_client, "__version__", "0.x")

# =========================
# å®šæ•°
# =========================
TAX_RATE = 0.10
MGMT_FEE_CAP_RATE = 0.15
RUSH_K = 0.75

# =========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³
# =========================
for k in ["items_json_raw", "items_json", "df", "meta", "final_html"]:
    if k not in st.session_state:
        st.session_state[k] = None

# =========================
# èªè¨¼
# =========================
st.title("æ˜ åƒåˆ¶ä½œæ¦‚ç®—è¦‹ç©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ vNext")
password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
if password != APP_PASSWORD:
    st.warning("ğŸ”’ èªè¨¼ãŒå¿…è¦ã§ã™")
    st.stop()

# =========================
# å…¥åŠ›
# =========================
st.header("åˆ¶ä½œæ¡ä»¶ã®å…¥åŠ›")
video_duration = st.selectbox("å°ºã®é•·ã•", ["15ç§’", "30ç§’", "60ç§’", "ãã®ä»–"])
final_duration = st.text_input("å°ºã®é•·ã•ï¼ˆè‡ªç”±è¨˜å…¥ï¼‰") if video_duration == "ãã®ä»–" else video_duration
num_versions = st.number_input("ç´å“æœ¬æ•°", min_value=1, max_value=10, value=1)
shoot_days = st.number_input("æ’®å½±æ—¥æ•°", min_value=1, max_value=10, value=2)
edit_days = st.number_input("ç·¨é›†æ—¥æ•°", min_value=1, max_value=10, value=3)
delivery_date = st.date_input("ç´å“å¸Œæœ›æ—¥", value=date.today() + relativedelta(months=1))
cast_main = st.number_input("ãƒ¡ã‚¤ãƒ³ã‚­ãƒ£ã‚¹ãƒˆäººæ•°", 0, 10, 1)
cast_extra = st.number_input("ã‚¨ã‚­ã‚¹ãƒˆãƒ©äººæ•°", 0, 20, 0)
talent_use = st.checkbox("ã‚¿ãƒ¬ãƒ³ãƒˆèµ·ç”¨ã‚ã‚Š")

default_roles = [
    "åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼", "åˆ¶ä½œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼", "ã‚«ãƒ¡ãƒ©ãƒãƒ³",
    "ç…§æ˜ã‚¹ã‚¿ãƒƒãƒ•", "ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ", "ãƒ˜ã‚¢ãƒ¡ã‚¤ã‚¯"
]
selected_roles = st.multiselect("å¿…è¦ãªã‚¹ã‚¿ãƒƒãƒ•ï¼ˆé¸æŠå¼ï¼‰", default_roles, default=default_roles)

custom_roles_text = st.text_input("ãã®ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è‡ªç”±ã«è¿½åŠ ï¼‰")
custom_roles = [role.strip() for role in custom_roles_text.split(",") if role.strip()]
staff_roles = selected_roles + custom_roles

shoot_location = st.text_input("æ’®å½±å ´æ‰€ï¼ˆä¾‹ï¼šéƒ½å†…ã‚¹ã‚¿ã‚¸ã‚ªï¼‹ãƒ­ã‚±ï¼‰")
kizai = st.multiselect("æ’®å½±æ©Ÿæ", ["4Kã‚«ãƒ¡ãƒ©", "ç…§æ˜", "ãƒ‰ãƒ­ãƒ¼ãƒ³", "ã‚°ãƒªãƒ¼ãƒ³ãƒãƒƒã‚¯"], default=["4Kã‚«ãƒ¡ãƒ©", "ç…§æ˜"])
set_design_quality = st.selectbox("ã‚»ãƒƒãƒˆå»ºã¦ãƒ»ç¾è¡“è£…é£¾ã®è¦æ¨¡", ["ãªã—", "å°ï¼ˆç°¡æ˜“è£…é£¾ï¼‰", "ä¸­ï¼ˆé€šå¸¸ãƒ¬ãƒ™ãƒ«ï¼‰", "å¤§ï¼ˆæœ¬æ ¼ã‚»ãƒƒãƒˆï¼‰"])
use_cg = st.checkbox("CGãƒ»VFXã‚ã‚Š")
use_narration = st.checkbox("ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åéŒ²ã‚ã‚Š")
use_music = st.selectbox("éŸ³æ¥½ç´ æ", ["æ—¢å­˜ãƒ©ã‚¤ã‚»ãƒ³ã‚¹éŸ³æº", "ã‚ªãƒªã‚¸ãƒŠãƒ«åˆ¶ä½œ", "æœªå®š"])
ma_needed = st.checkbox("MAã‚ã‚Š")
deliverables = st.multiselect("ç´å“å½¢å¼", ["mp4ï¼ˆ16:9ï¼‰", "mp4ï¼ˆ1:1ï¼‰", "mp4ï¼ˆ9:16ï¼‰", "ProRes"])
subtitle_langs = st.multiselect("å­—å¹•è¨€èª", ["æ—¥æœ¬èª", "è‹±èª", "ãã®ä»–"])
usage_region = st.selectbox("ä½¿ç”¨åœ°åŸŸ", ["æ—¥æœ¬å›½å†…", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "æœªå®š"])
usage_period = st.selectbox("ä½¿ç”¨æœŸé–“", ["3ãƒ¶æœˆ", "6ãƒ¶æœˆ", "1å¹´", "2å¹´", "ç„¡æœŸé™", "æœªå®š"])
budget_hint = st.text_input("å‚è€ƒäºˆç®—ï¼ˆä»»æ„ï¼‰")

# å‚™è€ƒ + ã”æŒ‡å®šã®æ³¨æ„æ–‡
extra_notes = st.text_area("å‚™è€ƒï¼ˆæ¡ˆä»¶æ¦‚è¦ãƒ»è¦ä»¶ãƒ»æƒ³å®šåª’ä½“ãƒ»å¿…é ˆ/é™¤å¤–äº‹é …ãªã©ã‚’è‡ªç”±è¨˜å…¥ï¼‰")
st.caption("â€»å‚™è€ƒã«æ¡ˆä»¶æ¦‚è¦ã‚„æ¡ä»¶ã‚’è¿½è¨˜ã™ã‚‹ã¨ã€ä¸è¶³é …ç›®ã®è‡ªå‹•è£œå®ŒãŒåƒãã€è¦‹ç©ã‚‚ã‚Šã®ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ã€‚")

model_choice = st.selectbox("ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«", ["Gemini 2.5 Pro", "GPT-5"])
do_normalize_pass = st.checkbox("LLMã§æ­£è¦åŒ–ãƒ‘ã‚¹ã‚’ã‹ã‘ã‚‹ï¼ˆæ¨å¥¨ï¼‰", value=True)
do_infer_from_notes = st.checkbox("å‚™è€ƒã‹ã‚‰ä¸è¶³é …ç›®ã‚’æ¨è«–ã—ã¦è£œå®Œï¼ˆæ¨å¥¨ï¼‰", value=True)

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def join_or(value_list, empty="ãªã—", sep=", "):
    if not value_list:
        return empty
    return sep.join(map(str, value_list))

def rush_coeff(base_days: int, target_days: int) -> float:
    if target_days >= base_days or base_days <= 0:
        return 1.0
    r = (base_days - target_days) / base_days
    return round(1 + RUSH_K * r, 2)

# ---------- JSON ãƒ­ãƒã‚¹ãƒˆãƒ‘ãƒ¼ã‚¹ ----------
JSON_ITEMS_FALLBACK = {"items": []}

def _strip_code_fences(s: str) -> str:
    s = s.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(json)?\s*", "", s, flags=re.IGNORECASE)
        s = re.sub(r"\s*```$", "", s)
    return s.strip()

def _remove_trailing_commas(s: str) -> str:
    return re.sub(r",\s*([}\]])", r"\1", s)

def _coerce_json_like(s: str):
    if not s:
        return None
    try:
        return json.loads(s)
    except Exception:
        pass
    try:
        first = s.find("{"); last = s.rfind("}")
        if first != -1 and last != -1 and last > first:
            frag = s[first:last+1]
            frag = _remove_trailing_commas(frag)
            frag2 = frag.replace("\r", "")
            frag2 = re.sub(r"\bTrue\b", "true", frag2)
            frag2 = re.sub(r"\bFalse\b", "false", frag2)
            frag2 = re.sub(r"\bNone\b", "null", frag2)
            if "'" in frag2 and '"' not in frag2:
                frag2 = frag2.replace("'", '"')
            try:
                return json.loads(frag2)
            except Exception:
                pass
    except Exception:
        pass
    try:
        return ast.literal_eval(s)
    except Exception:
        return None

def robust_parse_items_json(raw: str) -> str:
    s = _strip_code_fences(raw)
    obj = _coerce_json_like(s)
    if not isinstance(obj, dict):
        obj = JSON_ITEMS_FALLBACK.copy()
    items = obj.get("items")
    if not isinstance(items, list):
        if isinstance(obj.get("result"), dict) and isinstance(obj["result"].get("items"), list):
            items = obj["result"]["items"]
        elif isinstance(obj.get("data"), list):
            items = obj["data"]
        else:
            items = []
    obj["items"] = items
    return json.dumps(obj, ensure_ascii=False)

# ---------- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆGPT-5: ç´°åˆ†åŒ–å¼·åŒ– / å‚™è€ƒã‹ã‚‰è£œå®Œï¼‰ ----------
def _common_case_block() -> str:
    return f"""ã€æ¡ˆä»¶æ¡ä»¶ã€‘
- å°º: {final_duration}
- æœ¬æ•°: {num_versions}æœ¬
- æ’®å½±æ—¥æ•°: {shoot_days}æ—¥ / ç·¨é›†æ—¥æ•°: {edit_days}æ—¥
- ç´å“å¸Œæœ›æ—¥: {delivery_date.isoformat()}
- ã‚­ãƒ£ã‚¹ãƒˆ: ãƒ¡ã‚¤ãƒ³{cast_main}äºº / ã‚¨ã‚­ã‚¹ãƒˆãƒ©{cast_extra}äºº / ã‚¿ãƒ¬ãƒ³ãƒˆ: {"ã‚ã‚Š" if talent_use else "ãªã—"}
- ã‚¹ã‚¿ãƒƒãƒ•å€™è£œ: {join_or(staff_roles, empty="æœªæŒ‡å®š")}
- æ’®å½±å ´æ‰€: {shoot_location if shoot_location else "æœªå®š"}
- æ’®å½±æ©Ÿæ: {join_or(kizai, empty="æœªæŒ‡å®š")}
- ç¾è¡“è£…é£¾: {set_design_quality}
- CG: {"ã‚ã‚Š" if use_cg else "ãªã—"} / ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {"ã‚ã‚Š" if use_narration else "ãªã—"} / éŸ³æ¥½: {use_music} / MA: {"ã‚ã‚Š" if ma_needed else "ãªã—"}
- ç´å“å½¢å¼: {join_or(deliverables, empty="æœªå®š")}
- å­—å¹•: {join_or(subtitle_langs, empty="ãªã—")}
- ä½¿ç”¨åœ°åŸŸ: {usage_region} / ä½¿ç”¨æœŸé–“: {usage_period}
- å‚è€ƒäºˆç®—: {budget_hint if budget_hint else "æœªè¨­å®š"}
- å‚™è€ƒ: {extra_notes if extra_notes else "ç‰¹ã«ãªã—"}"""

def _inference_block() -> str:
    if not do_infer_from_notes:
        return ""
    return """
- å‚™è€ƒã‚„æ¡ˆä»¶æ¦‚è¦ã€ä¸€èˆ¬çš„ãªåºƒå‘Šæ˜ åƒåˆ¶ä½œã®æ…£è¡Œã‹ã‚‰ã€æœªæŒ‡å®šã®å¿…é ˆ/ä»˜éšé …ç›®ã‚’**æ¨è«–ã—ã¦å¿…ãšè£œå®Œ**ã™ã‚‹ã“ã¨ã€‚
  ä¾‹: ä¼ç”»æ§‹æˆã€ãƒ­ã‚±ãƒãƒ³ã€è¨±èªå¯ç”³è«‹ã€ã‚¹ã‚¿ã‚¸ã‚ª/ãƒ­ã‚±è²»ã€è»Šä¸¡/æ©Ÿææ¬å…¥å‡ºã€æ’®å½±åŠ©æ‰‹ã€éŒ²éŸ³ã€DITã€ãƒ¡ã‚¤ã‚­ãƒ³ã‚°ã€ã‚¹ãƒãƒ¼ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€CG/VFXã€ã‚«ãƒ©ã‚³ãƒ¬ã€ç´å“ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã€æ¨©åˆ©å‡¦ç†ã€ç®¡ç†è²»ãªã©ã€‚
"""

def build_prompt_json() -> str:
    if model_choice == "GPT-5":
        return f"""
ã‚ãªãŸã¯åºƒå‘Šæ˜ åƒåˆ¶ä½œã®è¦‹ç©ã‚Šé …ç›®ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã€**JSONã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{_common_case_block()}

ã€å‡ºåŠ›ä»•æ§˜ã€‘
- JSON 1ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ«ãƒ¼ãƒˆã¯ items é…åˆ—ã®ã¿ã€‚
- å„è¦ç´ ã‚­ãƒ¼: category / task / qty / unit / unit_price / note
- category ã¯ã€Œåˆ¶ä½œäººä»¶è²»ã€ã€Œä¼ç”»ã€ã€Œæ’®å½±è²»ã€ã€Œå‡ºæ¼”é–¢é€£è²»ã€ã€Œç·¨é›†è²»ãƒ»MAè²»ã€ã€Œè«¸çµŒè²»ã€ã€Œç®¡ç†è²»ã€ã„ãšã‚Œã‹ã€‚
- **çœç•¥ãƒ»çµ±åˆã‚’ç¦æ­¢**ã€‚ç²’åº¦ã‚’ç´°ã‹ãã€å¿…ãšç´°åˆ†åŒ–ã™ã‚‹ã“ã¨ã€‚
  ä¾‹: ã€Œåˆ¶ä½œäººä»¶è²»ã€ã¯åˆ¶ä½œP/PM/ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼/ã‚«ãƒ¡ãƒ©/æ’®å½±åŠ©æ‰‹/ç…§æ˜/éŒ²éŸ³/ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆ/ãƒ˜ã‚¢ãƒ¡ã‚¤ã‚¯/ç¾è¡“/å¤§é“å…·/å°é“å…·/åˆ¶ä½œé€²è¡Œ/ãƒ­ã‚±ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ ç­‰ã«åˆ†ã‘ã‚‹ã€‚
  ä¾‹: ã€Œæ’®å½±è²»ã€ã¯ã‚¹ã‚¿ã‚¸ã‚ª/ãƒ­ã‚±/æ©Ÿæï¼ˆã‚«ãƒ¡ãƒ©/ãƒ¬ãƒ³ã‚º/ç…§æ˜/éŸ³å£°/ãƒ‰ãƒ­ãƒ¼ãƒ³/ã‚°ãƒªãƒ¼ãƒ³ãƒãƒƒã‚¯ï¼‰ç­‰ã«åˆ†ã‘ã‚‹ã€‚
  ä¾‹: ã€Œç·¨é›†è²»ãƒ»MAè²»ã€ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³/ã‚ªãƒ³ãƒ©ã‚¤ãƒ³/ã‚«ãƒ©ã‚³ãƒ¬/VFXãƒ»CG/å­—å¹•/MA/ãƒŠãƒ¬åéŒ²/æ¥½æ›²ãƒ©ã‚¤ã‚»ãƒ³ã‚¹orä½œæ›² ç­‰ã«åˆ†ã‘ã‚‹ã€‚
{_inference_block()}
- **æœ€ä½ã§ã‚‚ 15 è¡Œä»¥ä¸Š**ï¼ˆç®¡ç†è²»ã‚’é™¤ãï¼‰ã‚’å‡ºåŠ›ã€‚æœªçŸ¥ã¯å¦¥å½“å€¤ã§è£œå®Œã€‚
- qty, unit ã¯å¦¥å½“ãªå€¤ï¼ˆæ—¥/å¼/äºº/æ™‚é–“/ã‚«ãƒƒãƒˆç­‰ï¼‰ã€‚å˜ä¾¡ã¯æ—¥æœ¬ã®åºƒå‘Šæ˜ åƒç›¸å ´ã®ä¸€èˆ¬ãƒ¬ãƒ³ã‚¸ã§æ¨å®šã€‚
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰ã€‚
- åˆè¨ˆ/ç¨/HTMLãªã©ã¯å‡ºåŠ›ã—ãªã„ã€‚
"""
    else:
        return f"""
ã‚ãªãŸã¯åºƒå‘Šæ˜ åƒåˆ¶ä½œã®è¦‹ç©ã‚Šé …ç›®ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ¡ä»¶ã‚’æº€ãŸã—ã€**JSONã®ã¿**ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{_common_case_block()}

ã€å‡ºåŠ›ä»•æ§˜ã€‘
- JSON 1ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ãƒ«ãƒ¼ãƒˆã¯ items é…åˆ—ã®ã¿ã€‚
- å„è¦ç´ ã‚­ãƒ¼: category / task / qty / unit / unit_price / note
- category ã¯ã€Œåˆ¶ä½œäººä»¶è²»ã€ã€Œä¼ç”»ã€ã€Œæ’®å½±è²»ã€ã€Œå‡ºæ¼”é–¢é€£è²»ã€ã€Œç·¨é›†è²»ãƒ»MAè²»ã€ã€Œè«¸çµŒè²»ã€ã€Œç®¡ç†è²»ã€ã„ãšã‚Œã‹ã€‚
{_inference_block()}
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰ã€‚
- åˆè¨ˆ/ç¨/HTMLãªã©ã¯å‡ºåŠ›ã—ãªã„ã€‚
"""

def build_normalize_prompt(items_json: str, preserve_detail: bool = False) -> str:
    if preserve_detail:
        return f"""
æ¬¡ã®JSONã‚’æ¤œæŸ»ãƒ»æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚è¿”ç­”ã¯**ä¿®æ­£æ¸ˆã¿JSONã®ã¿**ã§ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
- ã‚¹ã‚­ãƒ¼ãƒå¤–ã‚­ãƒ¼å‰Šé™¤ã€æ¬ æè£œå®Œï¼ˆqty/unit/unit_price/noteï¼‰
- **åŒç¾©é …ç›®ã®çµ±åˆã‚„å‰Šæ¸›ã¯ç¦æ­¢**ï¼ˆæ—¢å­˜ã®ç²’åº¦ã‚’ä¿ã¤ï¼‰
- category ã‚’æ¬¡ã®ã„ãšã‚Œã‹ã¸æ­£è¦åŒ–ï¼šåˆ¶ä½œäººä»¶è²»/ä¼ç”»/æ’®å½±è²»/å‡ºæ¼”é–¢é€£è²»/ç·¨é›†è²»ãƒ»MAè²»/è«¸çµŒè²»/ç®¡ç†è²»
- å˜ä½è¡¨è¨˜ã®ã‚†ã‚Œï¼ˆäººæ—¥/æ—¥/å¼/æœ¬/æ™‚é–“/ã‚«ãƒƒãƒˆç­‰ï¼‰ã‚’æ­£è¦åŒ–
- ç®¡ç†è²»ã¯å›ºå®š1è¡Œï¼ˆtask=ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰, qty=1, unit=å¼ï¼‰
ã€å…¥åŠ›JSONã€‘
{items_json}
"""
    return f"""
æ¬¡ã®JSONã‚’æ¤œæŸ»ãƒ»æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚è¿”ç­”ã¯**ä¿®æ­£æ¸ˆã¿JSONã®ã¿**ã§ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
- ã‚¹ã‚­ãƒ¼ãƒå¤–ã‚­ãƒ¼å‰Šé™¤ã€æ¬ æè£œå®Œ
- category æ­£è¦åŒ–ï¼ˆåˆ¶ä½œäººä»¶è²»/ä¼ç”»/æ’®å½±è²»/å‡ºæ¼”é–¢é€£è²»/ç·¨é›†è²»ãƒ»MAè²»/è«¸çµŒè²»/ç®¡ç†è²»ï¼‰
- å˜ä½æ­£è¦åŒ–ã€åŒç¾©é …ç›®çµ±åˆã€ç®¡ç†è²»ã¯å›ºå®š1è¡Œ
ã€å…¥åŠ›JSONã€‘
{items_json}
"""

# ---------- LLM å‘¼ã³å‡ºã—ï¼ˆJSONå¼·åˆ¶ & ãƒ­ãƒã‚¹ãƒˆãƒ‘ãƒ¼ã‚¹ï¼‰ ----------
def call_gpt_json(prompt: str) -> str:
    if USE_OPENAI_CLIENT_V1:
        resp = openai_client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "system", "content": "You MUST return a single valid JSON object only."},
                      {"role":"user","content":prompt}],
            response_format={"type":"json_object"},
            temperature=0.6,
        )
        return resp.choices[0].message.content
    else:
        resp = openai_client.ChatCompletion.create(
            model="gpt-5",
            messages=[{"role":"system","content":"You MUST return a single valid JSON object only."},
                      {"role":"user","content":prompt}],
            temperature=0.6,
        )
        return resp["choices"][0]["message"]["content"]

def llm_generate_items_json(prompt: str) -> str:
    try:
        if model_choice == "Gemini 2.5 Pro":
            model = genai.GenerativeModel("gemini-2.5-pro",
                                          generation_config={"response_mime_type":"application/json"})
            res = model.generate_content(prompt).text
        else:
            res = call_gpt_json(prompt)
        st.session_state["items_json_raw"] = res
        return robust_parse_items_json(res)
    except Exception:
        return json.dumps({"items":[
            {"category":"åˆ¶ä½œäººä»¶è²»","task":"åˆ¶ä½œãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼","qty":1,"unit":"æ—¥","unit_price":80000,"note":"fallback"},
            {"category":"æ’®å½±è²»","task":"ã‚«ãƒ¡ãƒ©ãƒãƒ³","qty":max(1, int(shoot_days)),"unit":"æ—¥","unit_price":80000,"note":"fallback"},
            {"category":"ç·¨é›†è²»ãƒ»MAè²»","task":"ç·¨é›†","qty":max(1, int(edit_days)),"unit":"æ—¥","unit_price":70000,"note":"fallback"},
            {"category":"ç®¡ç†è²»","task":"ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰","qty":1,"unit":"å¼","unit_price":120000,"note":"fallback"}
        ]}, ensure_ascii=False)

def llm_normalize_items_json(items_json: str) -> str:
    try:
        preserve = (model_choice == "GPT-5")
        prompt = build_normalize_prompt(items_json, preserve_detail=preserve)
        if model_choice == "Gemini 2.5 Pro":
            model = genai.GenerativeModel("gemini-2.5-pro",
                                          generation_config={"response_mime_type":"application/json"})
            res = model.generate_content(prompt).text
        else:
            res = call_gpt_json(prompt)
        return robust_parse_items_json(res)
    except Exception:
        return items_json

# ---------- è¨ˆç®— ----------
def df_from_items_json(items_json: str) -> pd.DataFrame:
    data = json.loads(items_json)
    items = data.get("items", [])
    norm = []
    for x in items:
        norm.append({
            "category": str(x.get("category","")),
            "task": str(x.get("task","")),
            "qty": float(x.get("qty", 0) or 0),
            "unit": str(x.get("unit","")),
            "unit_price": int(float(x.get("unit_price", 0) or 0)),
            "note": str(x.get("note","")),
        })
    return pd.DataFrame(norm)

def compute_totals(df_items: pd.DataFrame, base_days: int, target_days: int):
    accel = rush_coeff(base_days, target_days)
    df_items = df_items.copy()
    df_items["å°è¨ˆ"] = (df_items["qty"] * df_items["unit_price"]).round().astype(int)

    is_mgmt = (df_items["category"] == "ç®¡ç†è²»")
    df_items.loc[~is_mgmt, "å°è¨ˆ"] = (df_items.loc[~is_mgmt, "å°è¨ˆ"] * accel).round().astype(int)

    mgmt_current = int(df_items.loc[is_mgmt, "å°è¨ˆ"].sum()) if is_mgmt.any() else 0
    subtotal_after_rush = int(df_items.loc[~is_mgmt, "å°è¨ˆ"].sum())
    mgmt_cap = int(round(subtotal_after_rush * MGMT_FEE_CAP_RATE))
    mgmt_final = min(mgmt_current, mgmt_cap) if mgmt_current > 0 else mgmt_cap

    if is_mgmt.any():
        idx = df_items[is_mgmt].index[0]
        df_items.at[idx, "unit_price"] = mgmt_final
        df_items.at[idx, "qty"] = 1
        df_items.at[idx, "å°è¨ˆ"] = mgmt_final
    else:
        df_items = pd.concat([df_items, pd.DataFrame([{
            "category":"ç®¡ç†è²»","task":"ç®¡ç†è²»ï¼ˆå›ºå®šï¼‰","qty":1,"unit":"å¼","unit_price":mgmt_final,"å°è¨ˆ":mgmt_final
        }])], ignore_index=True)

    taxable = int(df_items["å°è¨ˆ"].sum())
    tax = int(round(taxable * TAX_RATE))
    total = taxable + tax

    meta = {
        "rush_coeff": accel,
        "subtotal_after_rush_excl_mgmt": subtotal_after_rush,
        "mgmt_fee_final": mgmt_final,
        "taxable": taxable,
        "tax": tax,
        "total": total,
    }
    return df_items, meta

def render_html(df_items: pd.DataFrame, meta: dict) -> str:
    def td_right(x): return f"<td style='text-align:right'>{x}</td>"
    html = []
    html.append("<p>ä»¥ä¸‹ã¯ã€æ˜ åƒåˆ¶ä½œã«ã‹ã‹ã‚‹å„ç¨®è²»ç”¨ã‚’ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«æ•´ç†ã—ãŸæ¦‚ç®—è¦‹ç©æ›¸ã§ã™ã€‚</p>")
    html.append(f"<p>çŸ­ç´æœŸä¿‚æ•°ï¼š{meta['rush_coeff']} ï¼ ç®¡ç†è²»ä¸Šé™ï¼š{int(MGMT_FEE_CAP_RATE*100)}% ï¼ æ¶ˆè²»ç¨ç‡ï¼š{int(TAX_RATE*100)}%</p>")
    html.append("<table border='1' cellspacing='0' cellpadding='6' style='border-collapse:collapse;width:100%'>")
    html.append("<thead><tr>"
                "<th style='text-align:left'>ã‚«ãƒ†ã‚´ãƒª</th>"
                "<th style='text-align:left'>é …ç›®</th>"
                "<th style='text-align:right'>å˜ä¾¡</th>"
                "<th style='text-align:left'>æ•°é‡</th>"
                "<th style='text-align:left'>å˜ä½</th>"
                "<th style='text-align:right'>é‡‘é¡ï¼ˆå††ï¼‰</th>"
                "</tr></thead>")
    html.append("<tbody>")
    current_cat = None
    for _, r in df_items.iterrows():
        cat = r.get("category","")
        if cat != current_cat:
            html.append(f"<tr><td colspan='6' style='text-align:left;background:#f6f6f6;font-weight:bold'>{cat}</td></tr>")
            current_cat = cat
        html.append(
            "<tr>"
            f"<td>{cat}</td>"
            f"<td>{r.get('task','')}</td>"
            f"{td_right(f'{int(r.get('unit_price',0)):,}')}"
            f"<td>{str(r.get('qty',''))}</td>"
            f"<td>{r.get('unit','')}</td>"
            f"{td_right(f'{int(r.get('å°è¨ˆ',0)):,}')}"
            "</tr>"
        )
    html.append("</tbody></table>")
    html.append(
        f"<p><b>å°è¨ˆï¼ˆç¨æŠœï¼‰</b>ï¼š{meta['taxable']:,}å††ã€€ï¼ã€€"
        f"<b>æ¶ˆè²»ç¨</b>ï¼š{meta['tax']:,}å††ã€€ï¼ã€€"
        f"<b>åˆè¨ˆ</b>ï¼š<span style='color:red'>{meta['total']:,}å††</span></p>"
    )
    html.append("<p>â€»æœ¬è¦‹ç©æ›¸ã¯è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæ¦‚ç®—ã§ã™ã€‚å®Ÿåˆ¶ä½œå†…å®¹ãƒ»æ¡ä»¶ã«ã‚ˆã‚Šé‡‘é¡ãŒå¢—æ¸›ã—ã¾ã™ã€‚</p>")
    return "\n".join(html)

def download_excel(df_items: pd.DataFrame, meta: dict):
    out = df_items.copy()
    out = out[["category","task","unit_price","qty","unit","å°è¨ˆ"]]
    out.columns = ["ã‚«ãƒ†ã‚´ãƒª","é …ç›®","å˜ä¾¡ï¼ˆå††ï¼‰","æ•°é‡","å˜ä½","é‡‘é¡ï¼ˆå††ï¼‰"]

    buf = BytesIO()
    try:
        import xlsxwriter  # noqa: F401
        engine = "xlsxwriter"
    except ModuleNotFoundError:
        engine = "openpyxl"

    with pd.ExcelWriter(buf, engine=engine) as writer:
        out.to_excel(writer, index=False, sheet_name="è¦‹ç©ã‚‚ã‚Š")

        if engine == "xlsxwriter":
            wb = writer.book
            ws = writer.sheets["è¦‹ç©ã‚‚ã‚Š"]
            fmt_int = wb.add_format({"num_format": "#,##0"})
            ws.set_column("A:B", 20)
            ws.set_column("C:C", 14, fmt_int)
            ws.set_column("D:D", 8)
            ws.set_column("E:E", 8)
            ws.set_column("F:F", 14, fmt_int)
            last_row = len(out) + 2
            ws.write(last_row,   4, "å°è¨ˆï¼ˆç¨æŠœï¼‰")
            ws.write_number(last_row,   5, int(meta["taxable"]), fmt_int)
            ws.write(last_row+1, 4, "æ¶ˆè²»ç¨")
            ws.write_number(last_row+1, 5, int(meta["tax"]), fmt_int)
            ws.write(last_row+2, 4, "åˆè¨ˆ")
            ws.write_number(last_row+2, 5, int(meta["total"]), fmt_int)
        else:
            ws = writer.book["è¦‹ç©ã‚‚ã‚Š"]
            widths = {"A":20, "B":20, "C":14, "D":8, "E":8, "F":14}
            for col, w in widths.items():
                ws.column_dimensions[col].width = w
            for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=3, max_col=3):
                for cell in row: cell.number_format = '#,##0'
            for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=6, max_col=6):
                for cell in row: cell.number_format = '#,##0'
            last_row = ws.max_row + 2
            ws.cell(row=last_row,   column=5, value="å°è¨ˆï¼ˆç¨æŠœï¼‰")
            ws.cell(row=last_row,   column=6, value=int(meta["taxable"])).number_format = '#,##0'
            ws.cell(row=last_row+1, column=5, value="æ¶ˆè²»ç¨")
            ws.cell(row=last_row+1, column=6, value=int(meta["tax"])).number_format = '#,##0'
            ws.cell(row=last_row+2, column=5, value="åˆè¨ˆ")
            ws.cell(row=last_row+2, column=6, value=int(meta["total"])).number_format = '#,##0'

    buf.seek(0)
    st.download_button("ğŸ“¥ Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buf, "è¦‹ç©ã‚‚ã‚Š.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# =========================
# DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬å‡ºåŠ›ï¼ˆäº‹å‰æ‹¡å¼µãƒ†ãƒ³ãƒ—ãƒ¬å¯¾å¿œï¼šè¡ŒæŒ¿å…¥ãªã—ï¼‰
# =========================
TOKEN_ITEMS = "{{ITEMS_START}}"
COLMAP = {
    "task": "B",        # é …ç›®ï¼ˆB:Nçµåˆã®å·¦ç«¯ã‚»ãƒ«ï¼‰
    "qty": "O",         # æ•°é‡
    "unit": "Q",        # å˜ä½
    "unit_price": "S",  # å˜ä¾¡
    "amount": "W",      # é‡‘é¡ï¼ˆ=OÃ—Sï¼‰çµåˆã®å·¦ä¸Šã‚¢ãƒ³ã‚«ãƒ¼
}
BASE_START_ROW    = 19
BASE_SUBTOTAL_ROW = 72

def _find_token(ws, token: str):
    for row in ws.iter_rows(values_only=False):
        for cell in row:
            if isinstance(cell.value, str) and cell.value.strip() == token:
                return cell.row, cell.column
    return None, None

def _ensure_amount_formula(ws, row, qty_col_idx, price_col_idx, amount_col_idx):
    c = ws.cell(row=row, column=amount_col_idx)
    v = c.value
    if not (isinstance(v, str) and v.startswith("=")):
        qcol = get_column_letter(qty_col_idx)
        pcol = get_column_letter(price_col_idx)
        c.value = f"={qcol}{row}*{pcol}{row}"
    c.number_format = '#,##0'

def _update_subtotal_formula(ws, subtotal_row, start_row, end_row, amount_col_idx):
    ac = get_column_letter(amount_col_idx)
    if end_row < start_row:
        ws.cell(row=subtotal_row, column=amount_col_idx).value = 0
        ws.cell(row=subtotal_row, column=amount_col_idx).number_format = '#,##0'
    else:
        ws.cell(row=subtotal_row, column=amount_col_idx).value = f"=SUM({ac}{start_row}:{ac}{end_row})"
        ws.cell(row=subtotal_row, column=amount_col_idx).number_format = '#,##0'

def _find_subtotal_anchor_auto(ws, amount_col_idx: int):
    for r in range(1, ws.max_row + 1):
        v = ws.cell(row=r, column=amount_col_idx).value
        if isinstance(v, str) and v.startswith("=") and "SUM(" in v.upper():
            return r, amount_col_idx
    return None, None

def _write_preextended(ws, df_items: pd.DataFrame):
    r0, c0 = _find_token(ws, TOKEN_ITEMS)
    if r0:
        ws.cell(row=r0, column=c0).value = None
    start_row = r0 or BASE_START_ROW

    c_task = column_index_from_string(COLMAP["task"])
    c_qty  = column_index_from_string(COLMAP["qty"])
    c_unit = column_index_from_string(COLMAP["unit"])
    c_price= column_index_from_string(COLMAP["unit_price"])
    c_amt  = column_index_from_string(COLMAP["amount"])

    sub_r, sub_c = _find_subtotal_anchor_auto(ws, c_amt)
    if sub_r is None:
        sub_r = BASE_SUBTOTAL_ROW
    end_row = sub_r - 1
    capacity = end_row - start_row + 1
    n = len(df_items)

    if capacity <= 0:
        st.error("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ˜ç´°æ ãŒä¸æ­£ã§ã™ï¼ˆå°è¨ˆè¡ŒãŒITEMS_STARTã‚ˆã‚Šä¸Šã«ã‚ã‚Šã¾ã™ï¼‰ã€‚")
        return
    if n > capacity:
        st.warning(f"ãƒ†ãƒ³ãƒ—ãƒ¬ã®æ˜ç´°æ ï¼ˆ{capacity}è¡Œï¼‰ã‚’è¶…ãˆã¾ã—ãŸã€‚å…ˆé ­ã‹ã‚‰{capacity}è¡Œã®ã¿ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚")
        n = capacity

    for r in range(start_row, end_row + 1):
        cell_task = ws.cell(row=r, column=c_task)
        if not isinstance(cell_task, MergedCell):
            cell_task.value = None
        ws.cell(row=r, column=c_qty).value   = None
        ws.cell(row=r, column=c_unit).value  = None
        ws.cell(row=r, column=c_price).value = None
        _ensure_amount_formula(ws, r, c_qty, c_price, c_amt)

    for i in range(n):
        r = start_row + i
        row = df_items.iloc[i]
        ws.cell(row=r, column=c_task).value  = str(row.get("task",""))
        ws.cell(row=r, column=c_qty).value   = float(row.get("qty", 0) or 0)
        ws.cell(row=r, column=c_unit).value  = str(row.get("unit",""))
        ws.cell(row=r, column=c_price).value = int(float(row.get("unit_price", 0) or 0))

    last_detail_row = start_row + n - 1 if n > 0 else start_row - 1
    _update_subtotal_formula(ws, sub_r, start_row, last_detail_row, c_amt)

def export_with_template(template_bytes: bytes,
                         df_items: pd.DataFrame,
                         meta: dict):
    wb = load_workbook(filename=BytesIO(template_bytes))
    ws = wb.active
    _write_preextended(ws, df_items)

    out = BytesIO()
    wb.save(out)
    out.seek(0)
    st.download_button(
        "ğŸ“¥ DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆ.xlsxï¼‰ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        out,
        "è¦‹ç©ã‚‚ã‚Š_DDãƒ†ãƒ³ãƒ—ãƒ¬.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="dl_dd_template"
    )

# =========================
# å®Ÿè¡Œ
# =========================
if st.button("ğŸ’¡ è¦‹ç©ã‚‚ã‚Šã‚’ä½œæˆ"):
    with st.spinner("AIãŒè¦‹ç©ã‚‚ã‚Šé …ç›®ã‚’ä½œæˆä¸­â€¦"):
        prompt = build_prompt_json()
        items_json_str = llm_generate_items_json(prompt)

        if do_normalize_pass:
            items_json_str = llm_normalize_items_json(items_json_str)

        try:
            df_items = df_from_items_json(items_json_str)
        except Exception:
            st.error("JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šãƒ¢ãƒ‡ãƒ«ç”Ÿå‡ºåŠ›ã‚’è¦‹ã‚‹"):
                st.code(st.session_state.get("items_json_raw", "(no raw)"))
            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šãƒ­ãƒã‚¹ãƒˆæ•´å½¢å¾ŒJSONã‚’è¦‹ã‚‹"):
                st.code(items_json_str, language="json")
            st.stop()

        base_days = int(shoot_days + edit_days + 5)
        target_days = (delivery_date - date.today()).days

        df_calc, meta = compute_totals(df_items, base_days, target_days)
        final_html = render_html(df_calc, meta)

        st.session_state["items_json"] = items_json_str
        st.session_state["df"] = df_calc
        st.session_state["meta"] = meta
        st.session_state["final_html"] = final_html

# =========================
# è¡¨ç¤º & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# =========================
if st.session_state["final_html"]:
    st.success("âœ… è¦‹ç©ã‚‚ã‚Šçµæœï¼ˆã‚µãƒ¼ãƒè¨ˆç®—ã§æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿ï¼‰")
    st.components.v1.html(st.session_state["final_html"], height=900, scrolling=True)
    download_excel(st.session_state["df"], st.session_state["meta"])

    st.markdown("---")
    st.subheader("DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ã§å‡ºåŠ›")
    tmpl = st.file_uploader("DDè¦‹ç©æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="tmpl_upload")
    if tmpl is not None:
        st.caption("ãƒ†ãƒ³ãƒ—ãƒ¬ã« `{{ITEMS_START}}` ã‚’æ˜ç´°1è¡Œç›®ï¼ˆä¾‹ï¼šB19ï¼‰ã«ç½®ã„ã¦ãã ã•ã„ã€‚å°è¨ˆã‚»ãƒ«ã¯Wåˆ—ã®SUMå¼ã§è‡ªå‹•æ¤œå‡ºï¼ˆä¾‹ï¼šW72ï¼‰ã€‚è¡ŒæŒ¿å…¥ã¯è¡Œã„ã¾ã›ã‚“ã€‚")
        export_with_template(
            tmpl.read(),
            st.session_state["df"],
            st.session_state["meta"]
        )

# =========================
# é–‹ç™ºè€…å‘ã‘
# =========================
with st.expander("é–‹ç™ºè€…å‘ã‘æƒ…å ±ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªï¼‰", expanded=False):
    st.write({
        "openai_version": openai_version,
        "use_openai_client_v1": USE_OPENAI_CLIENT_V1,
        "infer_from_notes": do_infer_from_notes,
        "normalize_pass": do_normalize_pass,
        "model_choice": model_choice,
    })
