# movietest_app.py
# =============================================
# Gemini 2.5 ç–é€šãƒ†ã‚¹ã‚¿ãƒ¼ï¼ˆ2.0ã¸è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
# - ã¾ãšã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ 2.5 ãŒé€šã‚‹ã‹ç¢ºèªã™ã‚‹æœ€å°å®Ÿè£…
# - requirements.txt ã¯ç¾çŠ¶ã®ã¾ã¾ã§OK
# - ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„
# =============================================

import os
import time
import json
from typing import Optional, Dict, Any

import streamlit as st
import google.generativeai as genai


# ============ åˆæœŸè¨­å®š ============
API_KEY = os.getenv("GEMINI_API_KEY", "")
st.set_page_config(page_title="Gemini 2.5 ãƒ†ã‚¹ãƒˆ", page_icon="ğŸ§ª", layout="wide")

if not API_KEY:
    st.error("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚Streamlit Cloud ã® Secrets ç­‰ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

genai.configure(api_key=API_KEY)

MODEL_CHOICES = [
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemini-2.0-flash",
]
DEFAULT_MODEL = "gemini-2.5-flash"
FALLBACK_MODEL = "gemini-2.0-flash"  # 2.5 ãŒè½ã¡ãŸã‚‰ã“ã“ã¸


# ============ ãƒšãƒ¼ã‚¸/ã‚µã‚¤ãƒ‰ãƒãƒ¼ UI ============
st.title("ğŸ§ª Gemini 2.5 ãƒ†ã‚¹ã‚¿ãƒ¼ï¼ˆè‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãï¼‰")

with st.sidebar:
    st.subheader("ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«", MODEL_CHOICES, index=MODEL_CHOICES.index(DEFAULT_MODEL))
    st.caption("2.5 ãŒä¸å®‰å®šãªå ´åˆã¯ 2.0 Flash ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

    st.subheader("å¿œç­”è¨­å®šï¼ˆä»»æ„ï¼‰")
    max_output_tokens = st.number_input("max_output_tokens", min_value=64, max_value=8192, value=1024, step=64)
    temperature = st.slider("temperature", min_value=0.0, max_value=2.0, value=0.6, step=0.1)

    force_json = st.toggle("JSON å½¢å¼ã§ã®å‡ºåŠ›ã‚’ä¿ƒã™ï¼ˆsystemç›¸å½“ã®ãƒ’ãƒ³ãƒˆã‚’å‰ç½®ï¼‰", value=False)

st.write(
    "1) ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ 2.5 ã‚’å®Ÿè¡Œ â†’ æˆåŠŸã™ã‚‹ã‹ç¢ºèª\n"
    "2) å¤±æ•—æ™‚ã¯ 2.0 ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆçµæœã‚¨ãƒªã‚¢ã«è¡¨ç¤ºï¼‰\n"
    "3) å®‰å®šã‚’ç¢ºèªå¾Œã€æ—¢å­˜ã‚¢ãƒ—ãƒªã¸æ®µéšçš„ã«çµ±åˆï¼ˆExcel å‡ºåŠ›ã¯åˆ¥é–¢æ•°åŒ–ãŒãŠã™ã™ã‚ï¼‰"
)

prompt = st.text_area(
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
    "2.5 ãŒæ­£å¸¸å¿œç­”ã™ã‚‹ã‹ã®å‹•ä½œç¢ºèªç”¨ãƒ†ã‚­ã‚¹ãƒˆã€‚å¿…è¦ãªã‚‰å…·ä½“ä¾‹ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚",
    height=180,
)


# ============ ãƒœã‚¿ãƒ³ UI ============
col_run, col_clear = st.columns(2)
with col_run:
    run_clicked = st.button("å®Ÿè¡Œ", type="primary", use_container_width=True)
with col_clear:
    clear_clicked = st.button("ã‚¯ãƒªã‚¢", use_container_width=True)


# ============ æ¨è«–ãƒ©ãƒƒãƒ‘é–¢æ•°ç¾¤ ============
def _generate(model_id: str, contents: str, *, max_tokens: int, temp: float):
    m = genai.GenerativeModel(model_id)
    return m.generate_content(
        contents,
        generation_config={
            "max_output_tokens": int(max_tokens),
            "temperature": float(temp),
        },
    )


def run_with_fallback(
    primary_model: str,
    contents: str,
    *,
    max_tokens: int,
    temp: float,
    fallback_model: str = FALLBACK_MODEL,
) -> Dict[str, Any]:
    out = {"ok": False, "model": primary_model, "fallback_used": False, "text": "", "raw": None}
    try:
        r = _generate(primary_model, contents, max_tokens=max_tokens, temp=temp)
        out.update({"ok": True, "text": getattr(r, "text", ""), "raw": r})
        return out
    except Exception as e:
        out["error_primary"] = repr(e)
        time.sleep(0.6)
        try:
            r2 = _generate(fallback_model, contents, max_tokens=max_tokens, temp=temp)
            out.update(
                {
                    "ok": True,
                    "model": fallback_model,
                    "fallback_used": True,
                    "text": getattr(r2, "text", ""),
                    "raw": r2,
                }
            )
            return out
        except Exception as e2:
            out["error_fallback"] = repr(e2)
            return out


# ============ å®Ÿè¡Œ/ã‚¯ãƒªã‚¢ ãƒ­ã‚¸ãƒƒã‚¯ ============
if run_clicked:
    if not prompt.strip():
        st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        final_prompt = (
            "ã‚ãªãŸã¯å³å¯†ãªJSONå‡ºåŠ›ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãš JSON ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\n"
            "æ—¥æœ¬èªã®èª¬æ˜æ–‡ã¯ JSON ã®å€¤ã®ä¸­ã ã‘ã«å«ã‚ã¦ãã ã•ã„ã€‚ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã¯ {\"result\": ...} æ§‹é€ ã«ã—ã¦ãã ã•ã„ã€‚\n\n"
        ) + prompt if force_json else prompt

        with st.spinner(f"{model_name} ã§å®Ÿè¡Œä¸­â€¦"):
            out = run_with_fallback(model_name, final_prompt, max_tokens=max_output_tokens, temp=temperature)

        status = ("æˆåŠŸ" if out.get("ok") else "å¤±æ•—") + ("ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Šï¼‰" if out.get("fallback_used") else "")
        if out.get("ok"):
            st.success(f"{status} / å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«: {out.get('model')}")
            st.write(out.get("text", ""))
        else:
            st.error(f"å¤±æ•— / å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«: {out.get('model')}")
            st.write("Primary error:", out.get("error_primary"))
            st.write("Fallback error:", out.get("error_fallback"))

if clear_clicked:
    st.session_state.clear()
    st.rerun()
